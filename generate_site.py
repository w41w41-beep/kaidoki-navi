import os
import shutil
import json
import math
import csv
from datetime import date
from dotenv import load_dotenv
import requests
import openai
from collections import defaultdict
import time
import re

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# ç’°å¢ƒå¤‰æ•°ã‚’å–å¾—
RAKUTEN_APP_ID = os.getenv("RAKUTEN_APP_ID")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
AMAZON_AFFILIATE_LINK = os.getenv("AMAZON_AFFILIATE_LINK")

# OpenAI APIã‚­ãƒ¼ã‚’è¨­å®š
openai.api_key = OPENAI_API_KEY

PRODUCTS_PER_PAGE = 10  # 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®å•†å“æ•°
OPENAI_MODEL = "gpt-4o-mini" # ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
PRODUCTS_CACHE_FILE = 'products_cache.json'
TAGS_CACHE_FILE = 'tags_cache.json'

# ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿
categories = {
    "å®¶é›»": ["ãƒ†ãƒ¬ãƒ“ãƒ»ãƒ¬ã‚³ãƒ¼ãƒ€ãƒ¼", "ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª", "ã‚«ãƒ¡ãƒ©", "å­£ç¯€ãƒ»ç©ºèª¿å®¶é›»", "ç”Ÿæ´»å®¶é›»", "ã‚­ãƒƒãƒãƒ³å®¶é›»", "ç†ç¾å®¹å®¶é›»", "å¥åº·å®¶é›»"],
    "PCãƒ»ã‚¹ãƒãƒ›": ["ãƒ‘ã‚½ã‚³ãƒ³", "ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆPC", "ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³", "PCå‘¨è¾ºæ©Ÿå™¨", "PCãƒ‘ãƒ¼ãƒ„ãƒ»ã‚½ãƒ•ãƒˆ"],
}

# ç‹¬è‡ªã®ã‚«ãƒ†ã‚´ãƒª
special_categories = {
    "æœ€å®‰å€¤": sorted(list(set(cat for sub_cats in categories.values() for cat in sub_cats))),
    "ã‚»ãƒ¼ãƒ«ãƒ»é™å®š": ["æœŸé–“é™å®š", "ç‰¹åˆ¥ã‚»ãƒ¼ãƒ«"],
}

# æ¥½å¤©APIã‹ã‚‰å•†å“ã‚’å–å¾—
def fetch_rakuten_items(keyword="å®¶é›»", genre_id="", hits=10):
    url = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20220601"
    params = {
        "applicationId": RAKUTEN_APP_ID,
        "keyword": keyword,
        "genreId": genre_id,
        "format": "json",
        "hits": hits,
        "sort": "-itemPrice",
        "availability": 0,
    }
    try:
        response = requests.get(url, params=params)
        response.raise_for_status()
        data = response.json()
        return data.get("Items", [])
    except requests.exceptions.RequestException as e:
        print(f"æ¥½å¤©APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return []

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®èª­ã¿è¾¼ã¿ã¨ä¿å­˜
def load_cache(file_path):
    if os.path.exists(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            try:
                return json.load(f)
            except json.JSONDecodeError:
                print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ« {file_path} ãŒç ´æã—ã¦ã„ã¾ã™ã€‚æ–°ã—ãä½œæˆã—ã¾ã™ã€‚")
                return {}
    return {}

def save_cache(data, file_path):
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

# AIåˆ†æã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°
def get_ai_analysis(product_data, existing_data=None):
    if existing_data is None:
        existing_data = {}

    current_price = product_data.get('price', 0)
    name = product_data.get('name', '')
    description = product_data.get('description', '')
    
    # ä¾¡æ ¼å±¥æ­´ã‹ã‚‰æœ€æ–°ä¾¡æ ¼ã¨éå»ä¾¡æ ¼ã‚’å–å¾—
    price_history = existing_data.get('price_history', [])
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ã€ç¾åœ¨ã®ä¾¡æ ¼ã‚’è¿½åŠ 
    if price_history:
        # é‡è¤‡ã™ã‚‹æ—¥ä»˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’é¿ã‘ã‚‹
        if price_history[-1]['date'] != date.today().isoformat():
            price_history.append({"date": date.today().isoformat(), "price": current_price})
    else:
        price_history = [{"date": date.today().isoformat(), "price": current_price}]

    # å¤‰æ›´ãƒ•ãƒ©ã‚°
    price_changed = False
    if len(price_history) > 1 and price_history[-2]['price'] != current_price:
        price_changed = True

    # æ–°è¦å•†å“ã¾ãŸã¯ä¾¡æ ¼ãŒå¤‰å‹•ã—ãŸå ´åˆã®ã¿AIåˆ†æã‚’å†å®Ÿè¡Œ
    if not existing_data or price_changed:
        price_analysis = "ç¾åœ¨ä¾¡æ ¼ã¯éå»ã¨æ¯”ã¹ã¦å®‰å®šã—ã¦ã„ã¾ã™ã€‚"
        if len(price_history) > 1:
            avg_price = sum(item['price'] for item in price_history) / len(price_history)
            max_price = max(item['price'] for item in price_history)
            min_price = min(item['price'] for item in price_history)
            
            if current_price < avg_price * 0.9:
                price_analysis = f"éå»ã®å¹³å‡ä¾¡æ ¼ï¼ˆç´„{int(avg_price):,}å††ï¼‰ã‚ˆã‚Š**å¤§å¹…ã«å®‰ããªã£ã¦ã„ã¾ã™ï¼** ä»ŠãŒè²·ã„æ™‚ã§ã™ï¼"
            elif current_price < min_price * 1.05:
                price_analysis = f"éå»æœ€å®‰å€¤ã«è¿‘ã„ä¾¡æ ¼ã§ã™ï¼ˆéå»æœ€å®‰å€¤ï¼š{int(min_price):,}å††ï¼‰ã€‚"
            elif current_price > avg_price * 1.1:
                price_analysis = f"éå»ã®å¹³å‡ä¾¡æ ¼ï¼ˆç´„{int(avg_price):,}å††ï¼‰ã‚ˆã‚Š**é«˜ããªã£ã¦ã„ã¾ã™**ã€‚ã‚‚ã†å°‘ã—å¾…ã¤ã®ãŒè³¢æ˜ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚"
        
        # GPTã«å•ã„åˆã‚ã›ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        try:
            prompt = (
                f"ã‚ãªãŸã¯å•†å“ã®è³¼è²·åˆ†æã‚’è¡Œã†AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®å•†å“ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã€"
                f"1. å•†å“ã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆï¼ˆAI Headlineï¼‰ã‚’15æ–‡å­—ç¨‹åº¦ã§ç°¡æ½”ã«æç¤ºã€‚"
                f"2. è²·ã„æ™‚åˆ†æï¼ˆAI Analysisï¼‰ã‚’50æ–‡å­—ã‹ã‚‰100æ–‡å­—ç¨‹åº¦ã§è©³ç´°ã«è§£èª¬ã€‚"
                f"3. å•†å“ã®ä¸»è¦ãªç‰¹å¾´ã‚’3ã¤ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼ˆAI Summaryï¼‰ã¨ã—ã¦ã€ãã‚Œãã‚Œ50æ–‡å­—ã‹ã‚‰100æ–‡å­—ç¨‹åº¦ã§ç®‡æ¡æ›¸ãå½¢å¼ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚ãƒã‚¤ãƒ©ã‚¤ãƒˆã¯ã€å•†å“ã®èª¬æ˜æ–‡ã‹ã‚‰å…·ä½“çš„ãªæ©Ÿèƒ½ã‚„ãƒ¡ãƒªãƒƒãƒˆã‚’æŠœç²‹ã—ã¦ãã ã•ã„ã€‚"
                f"4. 3ã€œ5å€‹ã®é–¢é€£ã™ã‚‹ã‚¿ã‚°ï¼ˆTagsï¼‰ã‚’ã€è¨˜å·ãªã—ã®å˜èªã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ä¾‹ï¼š['è»½é‡', 'é«˜æ©Ÿèƒ½', '4K']"
                f"5. é©åˆ‡ãªã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆSub Categoryï¼‰ã‚’ä¸€ã¤ã ã‘æ—¥æœ¬èªã§é¸ã‚“ã§ãã ã•ã„ã€‚ä¾‹ï¼š'ã‚­ãƒƒãƒãƒ³å®¶é›»'"
                f"\n\n---å•†å“æƒ…å ±---\nå•†å“å: {name}\nä¾¡æ ¼: {current_price}å††\nå•†å“è©³ç´°: {description}"
                f"\nä¾¡æ ¼åˆ†æ: {price_analysis}\n---"
                f"\n\nå›ç­”ã¯JSONå½¢å¼ã§ã€ã‚­ãƒ¼ã‚’ 'ai_headline', 'ai_analysis', 'ai_summary', 'tags', 'sub_category' ã¨ã—ã¦ãã ã•ã„ã€‚"
                f"ai_summaryã¯ç®‡æ¡æ›¸ãã‚’æ”¹è¡Œã¨åˆã‚ã›ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
            )

            completion = openai.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯ãƒ—ãƒ­ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆåˆ¶ä½œè€…ã§ã‚ã‚Šã€å•†å“ã®é­…åŠ›ã¨è²·ã„æ™‚ã‚’çš„ç¢ºã«ä¼ãˆã‚‹AIã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã«å³å¯†ã«å¾“ã£ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"}
            )
            analysis_result = json.loads(completion.choices[0].message.content)

            # AIã«ã‚ˆã‚‹è²·ã„æ™‚åˆ†æã«ä¾¡æ ¼åˆ†ææƒ…å ±ã‚’è¿½åŠ 
            analysis_result['ai_analysis'] = f"{analysis_result['ai_analysis']} {price_analysis}"
            
            return {
                'ai_headline': analysis_result.get('ai_headline', 'AIåˆ†ææº–å‚™ä¸­'),
                'ai_analysis': analysis_result.get('ai_analysis', 'è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚'),
                'ai_summary': analysis_result.get('ai_summary', 'ã“ã®å•†å“ã®è©³ã—ã„èª¬æ˜ã¯æº–å‚™ä¸­ã§ã™ã€‚'),
                'tags': analysis_result.get('tags', []),
                'sub_category': analysis_result.get('sub_category', 'ãã®ä»–'),
                'price_history': price_history
            }

        except Exception as e:
            print(f"AIåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return {
                'ai_headline': 'AIåˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ',
                'ai_analysis': 'AIåˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚',
                'ai_summary': 'AIåˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚',
                'tags': [],
                'sub_category': 'ãã®ä»–',
                'price_history': price_history
            }
    else:
        # ä¾¡æ ¼ãŒå¤‰å‹•ã—ã¦ã„ãªã„å ´åˆã¯ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å¿…è¦ãªæƒ…å ±ã‚’è¿”ã™
        return {
            'ai_headline': existing_data.get('ai_headline'),
            'ai_analysis': existing_data.get('ai_analysis'),
            'ai_summary': existing_data.get('ai_summary'),
            'tags': existing_data.get('tags'),
            'sub_category': existing_data.get('sub_category'),
            'price_history': price_history
        }


def update_products_csv(rakuten_products):
    products_cache = load_cache(PRODUCTS_CACHE_FILE)
    
    updated_products = []
    
    for item in rakuten_products:
        item_data = item['Item']
        item_code = item_data['itemCode']
        
        # æ—¢å­˜ã®å•†å“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ç¢ºèª
        existing_product = products_cache.get(item_code)
        
        # æ–°ã—ã„ä¾¡æ ¼
        current_price = int(item_data['itemPrice'])
        
        product = {
            'name': item_data['itemName'],
            'price': current_price,
            'url': item_data['itemUrl'],
            'image_url': item_data['mediumImageUrls'][0]['imageUrl'],
            'description': item_data['itemCaption'],
            'page_url': f"products/{item_code.replace(':', '_')}.html", # URLã®ç‰¹æ®Šæ–‡å­—ã‚’ç½®ãæ›ãˆã‚‹
            'rakuten_url': item_data['itemUrl'],
            'item_code': item_code,
            'category': {
                'main': 'ãã®ä»–',
                'sub': 'ãã®ä»–'
            },
            'tags': [],
            'ai_headline': '',
            'ai_analysis': '',
            'ai_summary': '',
            'price_history': []
        }
        
        # AIåˆ†æã‚’å®Ÿè¡Œ
        ai_data = get_ai_analysis(product, existing_product)
        
        # AIåˆ†æçµæœã‚’å•†å“ãƒ‡ãƒ¼ã‚¿ã«çµ±åˆ
        product.update(ai_data)

        # ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‹ã‚‰ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’è‡ªå‹•è¨­å®š
        for main_cat, sub_cats in categories.items():
            if product['category']['sub'] in sub_cats:
                product['category']['main'] = main_cat
                break

        updated_products.append(product)
        
    # æ–°ã—ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    new_products_cache = {p['item_code']: p for p in updated_products}
    save_cache(new_products_cache, PRODUCTS_CACHE_FILE)
    
    return updated_products

# é™çš„ã‚µã‚¤ãƒˆç”Ÿæˆ
def generate_site(products):
    
    def generate_header_footer(page_path, sub_cat_links=None, page_title="ãŠå¾—ãªå•†å“ã®è²·ã„æ™‚ã‚’ãƒŠãƒ“ã‚²ãƒ¼ãƒˆï¼"):
        main_links_html = """
            <a href="{base_path}index.html">ãƒˆãƒƒãƒ—</a><span class="separator">|</span>
            <a href="{base_path}category/å®¶é›».html">å®¶é›»</a><span class="separator">|</span>
            <a href="{base_path}category/PCãƒ»ã‚¹ãƒãƒ›.html">PCãƒ»ã‚¹ãƒãƒ›</a><span class="separator">|</span>
            <a href="{base_path}category/æœ€å®‰å€¤.html">æœ€å®‰å€¤</a><span class="separator">|</span>
            <a href="{base_path}category/ã‚»ãƒ¼ãƒ«ãƒ»é™å®š.html">ã‚»ãƒ¼ãƒ«ãƒ»é™å®š</a><span class="separator">|</span>
            <a href="{base_path}tags/index.html">ã‚¿ã‚°ã‹ã‚‰æ¢ã™</a>
        """
        
        base_path = os.path.relpath('.', os.path.dirname(page_path)).replace('\\', '/')
        if base_path != '.':
            base_path += '/'
        else:
            base_path = './'
        
        header_html = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“ | {page_title}</title>
    <link rel="stylesheet" href="{base_path}style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <meta name="google-site-verification" content="OmUuOjcxi7HXBKe47sd0WPbzCfbCOFbPj_iueHBk2qo" />
</head>
<body>
    <header>
        <div class="container">
            <h1><a href="{base_path}index.html">ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“</a></h1>
            <p>ãŠå¾—ãªè²·ã„æ™‚ã‚’è¦‹ã¤ã‘ã‚ˆã†ï¼</p>
        </div>
    </header>
    <div class="search-bar">
        <div class="search-container">
            <input type="text" placeholder="å•†å“åã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢..." class="search-input">
            <button class="search-button">ğŸ”</button>
        </div>
    </div>
    <div class="genre-links-container">
        <div class="genre-links">
            {main_links_html}
        </div>
    </div>
    <div class="genre-links-container" style="margin-top: -10px;">
        <div class="genre-links">
            {'' if sub_cat_links is None else "".join([f'<a href="{base_path}category/{sub_cat.replace(" ", "")}.html">{sub_cat}</a><span class="separator">|</span>' for sub_cat in sorted(sub_cat_links)])}
        </div>
    </div>
"""
        footer_html = f"""
    </main>
    <footer>
        <p>&copy; 2025 ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“. All Rights Reserved.</p>
        <div class="footer-links">
            <a href="{base_path}privacy.html">ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼</a>
            <a href="{base_path}disclaimer.html">å…è²¬äº‹é …</a>
            <a href="{base_path}contact.html">ãŠå•ã„åˆã‚ã›</a>
        </div>
    </footer>
    <script src="{base_path}script.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {{
            const priceChartCanvas = document.getElementById('priceChart');
            if (priceChartCanvas) {{
                const dataHistory = JSON.parse(priceChartCanvas.getAttribute('data-history'));
                const dates = dataHistory.map(item => item.date);
                const prices = dataHistory.map(item => item.price);

                new Chart(priceChartCanvas, {{
                    type: 'line',
                    data: {{
                        labels: dates,
                        datasets: [{{
                            label: 'ä¾¡æ ¼æ¨ç§»',
                            data: prices,
                            borderColor: 'rgb(75, 192, 192)',
                            tension: 0.1
                        }}]
                    }},
                    options: {{
                        responsive: true,
                        scales: {{
                            x: {{
                                title: {{
                                    display: true,
                                    text: 'æ—¥ä»˜'
                                }}
                            }},
                            y: {{
                                title: {{
                                    display: true,
                                    text: 'ä¾¡æ ¼ï¼ˆå††ï¼‰'
                                }}
                            }}
                        }}
                    }}
                }});
            }}
        }});
    </script>
</body>
</html>
"""
        return header_html, footer_html

    def generate_static_page(file_name, title, content_html):
        page_path = file_name
        header, footer = generate_header_footer(page_path, page_title=title)
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + content_html + footer)
        print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    # æ—¢å­˜ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    for root, dirs, files in os.walk('.'):
        for file in files:
            if file.endswith('.html') and not file in ['privacy.html', 'disclaimer.html', 'contact.html', 'sitemap.xml', 'index.html', 'style.css', 'script.js']:
                os.remove(os.path.join(root, file))
    if os.path.exists('category'):
        shutil.rmtree('category', ignore_errors=True)
    if os.path.exists('pages'):
        shutil.rmtree('pages', ignore_errors=True)
    if os.path.exists('tags'):
        shutil.rmtree('tags', ignore_errors=True)
    if os.path.exists('products'):
        shutil.rmtree('products', ignore_errors=True)

    os.makedirs('products', exist_ok=True)
    os.makedirs('category', exist_ok=True)
    os.makedirs('tags', exist_ok=True)

    # ä¸€èˆ¬ã‚«ãƒ†ã‚´ãƒªã®ãƒšãƒ¼ã‚¸ç”Ÿæˆ
    for main_cat, sub_cats in categories.items():
        main_cat_products = [p for p in products if p.get('category', {}).get('main', '') == main_cat]
        page_path = f"category/{main_cat.replace(' ', '')}.html"
        header, footer = generate_header_footer(page_path, sub_cat_links=sub_cats, page_title=f"{main_cat}ã®å•†å“ä¸€è¦§")
        main_content_html = f"""
    <main class="container">
        <div class="ai-recommendation-section">
            <h2 class="ai-section-title">{main_cat}ã®å•†å“ä¸€è¦§</h2>
            <div class="product-grid">
            """
        products_html = ""
        for product in main_cat_products:
            link_path = os.path.relpath(product['page_url'], os.path.dirname(page_path))
            products_html += f"""
<a href="{link_path}" class="product-card">
    <img src="{product.get('image_url', '')}" alt="{product.get('name', 'å•†å“ç”»åƒ')}">
    <div class="product-info">
        <h3 class="product-name">{product.get('name', 'å•†å“å')[:20] + '...' if len(product.get('name', '')) > 20 else product.get('name', 'å•†å“å')}</h3>
        <p class="product-price">{int(product.get('price', 0)):,}å††</p>
        <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
        <div class="price-status-content ai-analysis">{product.get('ai_headline', 'AIåˆ†ææº–å‚™ä¸­')}</div>
    </div>
</a>
            """
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + main_content_html + products_html + "</div></div>" + footer)
        print(f"category/{main_cat.replace(' ', '')}.html ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    # ç‹¬è‡ªã®ã‚«ãƒ†ã‚´ãƒªã®ãƒšãƒ¼ã‚¸ç”Ÿæˆ
    for special_cat, sub_cats in special_categories.items():
        page_path = f"category/{special_cat.replace(' ', '')}.html"
        header, footer = generate_header_footer(page_path, sub_cat_links=sub_cats, page_title=f"{special_cat}ã®å•†å“ä¸€è¦§")

        main_content_html = f"""
    <main class="container">
        <div class="ai-recommendation-section">
            <h2 class="ai-section-title">{special_cat}ã®ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ä¸€è¦§</h2>
            <div class="genre-links sub-genre-links">
            {"".join([f'<a href="{sub_cat.replace(" ", "")}.html">{sub_cat}</a><span class="separator">|</span>' for sub_cat in sorted(sub_cats)])}
            </div>
        </div>
    """
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + main_content_html + "</main>" + footer)
        print(f"category/{special_cat.replace(' ', '')}.html ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
        
        for sub_cat in sub_cats:
            sub_cat_file_name = f"{sub_cat.replace(' ', '')}.html"
            page_path = f"category/{sub_cat_file_name}"
            
            # æœ€å®‰å€¤ã‚«ãƒ†ã‚´ãƒªã®å•†å“ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if special_cat == 'æœ€å®‰å€¤':
                filtered_products = [p for p in products if p.get('category', {}).get('sub', '') == sub_cat]
                filtered_products.sort(key=lambda x: int(x.get('price', 0)))  # ä¾¡æ ¼ãŒä½ã„é †ã«ã‚½ãƒ¼ãƒˆ
            else:  # æœŸé–“é™å®šã‚»ãƒ¼ãƒ«ãªã©
                filtered_products = [p for p in products if p.get('category', {}).get('sub', '') == sub_cat and any(tag in ['ã‚»ãƒ¼ãƒ«', 'æœŸé–“é™å®š'] for tag in p.get('tags', []))]

            header, footer = generate_header_footer(page_path, page_title=f"{special_cat} > {sub_cat}ã®å•†å“ä¸€è¦§")
            main_content_html = f"""
    <main class="container">
        <div class="ai-recommendation-section">
            <h2 class="ai-section-title">{sub_cat}ã®ãŠå¾—ãªå•†å“ä¸€è¦§</h2>
            <div class="product-grid">
            """
            products_html = ""
            for product in filtered_products:
                link_path = os.path.relpath(product['page_url'], os.path.dirname(page_path))
                products_html += f"""
<a href="{link_path}" class="product-card">
    <img src="{product.get('image_url', '')}" alt="{product.get('name', 'å•†å“ç”»åƒ')}">
    <div class="product-info">
        <h3 class="product-name">{product.get('name', 'å•†å“å')[:20] + '...' if len(product.get('name', '')) > 20 else product.get('name', 'å•†å“å')}</h3>
        <p class="product-price">{int(product.get('price', 0)):,}å††</p>
        <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
        <div class="price-status-content ai-analysis">{product.get('ai_headline', 'AIåˆ†ææº–å‚™ä¸­')}</div>
    </div>
</a>
                """
            with open(page_path, 'w', encoding='utf-8') as f:
                f.write(header + main_content_html + products_html + "</div></div>" + footer)
            print(f"category/{sub_cat_file_name} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")

    # ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã¨ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ
    total_pages = math.ceil(len(products) / PRODUCTS_PER_PAGE)
    for i in range(total_pages):
        start_index = i * PRODUCTS_PER_PAGE
        end_index = start_index + PRODUCTS_PER_PAGE
        paginated_products = products[start_index:end_index]
        page_num = i + 1
        page_path = 'index.html' if page_num == 1 else f'pages/page{page_num}.html'
        if page_num > 1:
            os.makedirs(os.path.dirname(page_path), exist_ok=True)
        header, footer = generate_header_footer(page_path)
        products_html = ""
        for product in paginated_products:
            link_path = os.path.relpath(product['page_url'], os.path.dirname(page_path))
            products_html += f"""
<a href="{link_path}" class="product-card">
    <img src="{product.get('image_url', '')}" alt="{product.get('name', 'å•†å“ç”»åƒ')}">
    <div class="product-info">
        <h3 class="product-name">{product.get('name', 'å•†å“å')[:20] + '...' if len(product.get('name', '')) > 20 else product.get('name', 'å•†å“å')}</h3>
        <p class="product-price">{int(product.get('price', 0)):,}å††</p>
        <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
        <div class="price-status-content ai-analysis">{product.get('ai_headline', 'AIåˆ†ææº–å‚™ä¸­')}</div>
    </div>
</a>
            """
        pagination_html = ""
        if total_pages > 1:
            pagination_html += '<div class="pagination">'
            if page_num > 1:
                prev_link = 'index.html' if page_num == 2 else f'pages/page{page_num - 1}.html'
                pagination_html += f'<a href="{os.path.relpath(prev_link, os.path.dirname(page_path))}" class="prev">å‰ã¸</a>'
            for p in range(1, total_pages + 1):
                page_link = 'index.html' if p == 1 else f'pages/page{p}.html'
                active_class = 'active' if p == page_num else ''
                pagination_html += f'<a href="{os.path.relpath(page_link, os.path.dirname(page_path))}" class="{active_class}">{p}</a>'
            if page_num < total_pages:
                next_link = f'pages/page{page_num + 1}.html'
                pagination_html += f'<a href="{os.path.relpath(next_link, os.path.dirname(page_path))}" class="next">æ¬¡ã¸</a>'
            pagination_html += '</div>'
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + '<main class="container"><div class="ai-recommendation-section"><h2 class="ai-section-title">ä»ŠãŒè²·ã„æ™‚ï¼ãŠå¾—ãªæ³¨ç›®ã‚¢ã‚¤ãƒ†ãƒ </h2><div class="product-grid">' + products_html + '</div>' + pagination_html + '</main>' + footer)
        print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    # å€‹åˆ¥å•†å“ãƒšãƒ¼ã‚¸ã®ç”Ÿæˆ
    for product in products:
        page_path = product['page_url']
        dir_name = os.path.dirname(page_path)
        if dir_name:
            os.makedirs(dir_name, exist_ok=True)
        header, footer = generate_header_footer(page_path, page_title=f"{product.get('name', 'å•†å“å')}ã®è²·ã„æ™‚æƒ…å ±")
        ai_analysis_block_html = f"""
            <div class="ai-analysis-block">
                <div class="ai-analysis-text">
                    <h2>AIã«ã‚ˆã‚‹è²·ã„æ™‚åˆ†æ</h2>
                    <p>{product.get('ai_analysis', 'è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚')}</p>
                </div>
            </div>
        """
        specs_html = ""
        if "specs" in product:
            specs_html = f"""
                <div class="item-specs">
                    <h2>è£½å“ä»•æ§˜ãƒ»ã‚¹ãƒšãƒƒã‚¯</h2>
                    <p>{product.get('specs', '')}</p>
                </div>
            """
        # ä¾¡æ ¼å±¥æ­´ãŒç©ºã®å ´åˆã€ç¾åœ¨ä¾¡æ ¼ã‚’æœ€åˆã®ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è¿½åŠ 
        price_history_for_chart = product.get('price_history', [])
        if not price_history_for_chart:
            try:
                price_int = int(str(product['price']).replace(',', ''))
                price_history_for_chart = [{"date": date.today().isoformat(), "price": price_int}]
            except (ValueError, KeyError):
                price_history_for_chart = []

        price_history_json = json.dumps(price_history_for_chart)
        price_chart_html = f"""
        <div class="price-chart-section">
            <h2>ä¾¡æ ¼æ¨ç§»ã‚°ãƒ©ãƒ•</h2>
            <canvas id="priceChart" data-history='{price_history_json}'></canvas>
        </div>
        """
        purchase_button_html = f"""
        <div class="purchase-buttons">
            <a href="{product.get('rakuten_url', '')}" class="purchase-button rakuten" target="_blank">æ¥½å¤©å¸‚å ´ã§è³¼å…¥ã™ã‚‹</a>
        </div>
        """

        affiliate_links_html = f"""
            <div class="lowest-price-section">
                <p class="lowest-price-label">æœ€å®‰å€¤ã‚·ãƒ§ãƒƒãƒ—ã‚’ãƒã‚§ãƒƒã‚¯ï¼</p>
                <div class="lowest-price-buttons">
                    <a href="{AMAZON_AFFILIATE_LINK}" class="btn shop-link amazon" target="_blank">Amazonã§è¦‹ã‚‹</a>
                    <a href="{product.get("rakuten_url", "https://www.rakuten.co.jp/")}" class="btn shop-link rakuten" target="_blank">æ¥½å¤©å¸‚å ´ã§è¦‹ã‚‹</a>
                    <a href="{product.get("yahoo_url", "https://shopping.yahoo.co.jp/")}" class="btn shop-link yahoo" target="_blank">Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã§è¦‹ã‚‹</a>
                </div>
            </div>
        """
        item_html_content = f"""
<main class="container">
    <div class="product-detail">
        <div class="item-detail">
            <div class="item-image">
                <img src="{product.get('image_url', '')}" alt="{product.get('name', 'å•†å“ç”»åƒ')}" class="main-product-image">
            </div>
            <div class="item-info">
                <h1 class="item-name">{product.get('name', 'å•†å“å')}</h1>
                <p class="item-category">ã‚«ãƒ†ã‚´ãƒªï¼š<a href="{os.path.relpath('category/' + product.get('category', {}).get('main', '').replace(' ', '') + '.html', os.path.dirname(page_path))}">{product.get('category', {}).get('main', '')}</a> &gt; <a href="{os.path.relpath('category/' + product.get('category', {}).get('sub', '').replace(' ', '') + '.html', os.path.dirname(page_path))}">{product.get('category', {}).get('sub', '')}</a></p>
                <div class="price-section">
                    <p class="current-price">ç¾åœ¨ã®ä¾¡æ ¼ï¼š<span>{int(product.get('price', 0)):,}</span>å††</p>
                </div>
                <div class="ai-recommendation-section">
                    <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
                    <div class="price-status-content ai-analysis">{product.get('ai_headline', 'AIåˆ†ææº–å‚™ä¸­')}</div>
                </div>
                {purchase_button_html}
                {ai_analysis_block_html}
                {price_chart_html}
                {affiliate_links_html}
                <div class="item-description">
                    <h2>AIã«ã‚ˆã‚‹å•†å“ãƒã‚¤ãƒ©ã‚¤ãƒˆ</h2>
                    <p>{product.get('ai_summary', 'ã“ã®å•†å“ã®è©³ã—ã„èª¬æ˜ã¯æº–å‚™ä¸­ã§ã™ã€‚')}</p>
                </div>
                {specs_html}
                <div class="product-tags">
                    {"".join([f'<a href="{os.path.relpath("tags/" + tag.replace(" ", "") + ".html", os.path.dirname(page_path))}" class="tag-button">#{tag}</a>' for tag in product.get('tags', [])])}
                </div>
            </div>
        </div>
    </div>
</main>
"""
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + item_html_content + footer)
        print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    # ã‚¿ã‚°é–¢é€£ãƒšãƒ¼ã‚¸ã®ç”Ÿæˆ
    all_tags = sorted(list(set(tag for product in products for tag in product.get('tags', []))))

    if all_tags:
        os.makedirs('tags', exist_ok=True)
        tag_list_html_content = f"""
<main class="container">
    <div class="ai-recommendation-section">
        <h2 class="ai-section-title">ã‚¿ã‚°ã‹ã‚‰æ¢ã™</h2>
        <div class="product-tags all-tags-list">
            {"".join([f'<a href="{tag.replace(" ", "")}.html" class="tag-button">#{tag}</a>' for tag in all_tags])}
        </div>
    </div>
</main>
"""
        tag_header, tag_footer = generate_header_footer('tags/index.html', page_title="ã‚¿ã‚°ä¸€è¦§")
        with open('tags/index.html', 'w', encoding='utf-8') as f:
            f.write(tag_header + tag_list_html_content + tag_footer)
        print("ã‚¿ã‚°ä¸€è¦§ãƒšãƒ¼ã‚¸: tags/index.html ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")

        for tag in all_tags:
            tag_page_path = f'tags/{tag.replace(" ", "")}.html'
            tag_products = [product for product in products if tag in product.get('tags', [])]
            tag_page_content = f"""
<main class="container">
    <div class="ai-recommendation-section">
        <h2 class="ai-section-title">#{tag} ã®å•†å“ä¸€è¦§</h2>
        <div class="product-grid">
            {"".join([f'''
            <a href="{os.path.relpath(product.get('page_url', ''), os.path.dirname(tag_page_path))}" class="product-card">
                <img src="{product.get('image_url', '')}" alt="{product.get('name', 'å•†å“ç”»åƒ')}">
                <div class="product-info">
                    <h3 class="product-name">{product.get('name', 'å•†å“å')[:20] + '...' if len(product.get('name', '')) > 20 else product.get('name', 'å•†å“å')}</h3>
                    <p class="product-price">{int(product.get('price', 0)):,}å††</p>
                    <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
                    <div class="price-status-content ai-analysis">{product.get('ai_headline', 'AIåˆ†ææº–å‚™ä¸­')}</div>
                </div>
            </a>
            ''' for product in tag_products])}
        </div>
    </div>
</main>
"""
            tag_header, tag_footer = generate_header_footer(tag_page_path, page_title=f"#{tag} ã®å•†å“ä¸€è¦§")
            with open(tag_page_path, 'w', encoding='utf-8') as f:
                f.write(tag_header + tag_page_content + tag_footer)
            print(f"ã‚¿ã‚°ãƒšãƒ¼ã‚¸: {tag_page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")

    # é™çš„ãƒšãƒ¼ã‚¸ï¼ˆãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã€å…è²¬äº‹é …ã€ãŠå•ã„åˆã‚ã›ï¼‰ã®ç”Ÿæˆ
    contact_content = """
    <main class="container">
        <div class="static-content">
            <h1>ãŠå•ã„åˆã‚ã›</h1>
            <p>ã”è³ªå•ã‚„ã”è¦æœ›ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€ä»¥ä¸‹ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¾ã§ã”é€£çµ¡ãã ã•ã„ã€‚</p>
            <p>ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹: sokux001@gmail.com</p>
        </div>
    </main>
    """
    generate_static_page("contact.html", "ãŠå•ã„åˆã‚ã›", contact_content)
    privacy_content = """
    <main class="container">
        <div class="static-content">
            <h1>ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼</h1>
            <p>å½“ã‚µã‚¤ãƒˆã¯ã€Googleã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚åé›†ã•ã‚Œã‚‹æƒ…å ±ã‚„ãã®åˆ©ç”¨ç›®çš„ã«ã¤ã„ã¦ã¯ã€Googleã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã‚’ã”ç¢ºèªãã ã•ã„ã€‚</p>
            <p>å½“ã‚µã‚¤ãƒˆã¯ã€Amazon.co.jpã€æ¥½å¤©å¸‚å ´ã€Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚’å®£ä¼ã—ãƒªãƒ³ã‚¯ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã‚µã‚¤ãƒˆãŒç´¹ä»‹æ–™ã‚’ç²å¾—ã§ãã‚‹æ‰‹æ®µã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã«è¨­å®šã•ã‚ŒãŸã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å‚åŠ è€…ã§ã™ã€‚</p>
        </div>
    </main>
    """
    generate_static_page("privacy.html", "ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼", privacy_content)
    disclaimer_content = """
    <main class="container">
        <div class="static-content">
            <h1>å…è²¬äº‹é …</h1>
            <p>æœ¬ã‚µã‚¤ãƒˆã«æ²è¼‰ã•ã‚Œã¦ã„ã‚‹æƒ…å ±ã¯ã€æ­£ç¢ºæ€§ã‚„å®Œå…¨æ€§ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</p>
            <p>ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ã‚’é€šã˜ã¦è³¼å…¥ã•ã‚ŒãŸå•†å“ã«é–¢ã™ã‚‹ãƒˆãƒ©ãƒ–ãƒ«ã«ã¤ã„ã¦ã¯ã€å½“ã‚µã‚¤ãƒˆã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</p>
        </div>
    </main>
    """
    generate_static_page("disclaimer.html", "å…è²¬äº‹é …", disclaimer_content)

    # ã‚µã‚¤ãƒˆãƒãƒƒãƒ—ã®ç”Ÿæˆ
    def create_sitemap():
        base_url = "https://w41w41-beep.github.io/kaidoki-navi/"
        sitemap_content = '<?xml version="1.0" encoding="UTF-8"?>\n'
        sitemap_content += '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'
        sitemap_content += '  <url>\n'
        sitemap_content += f'    <loc>{base_url}</loc>\n'
        sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
        sitemap_content += '    <changefreq>daily</changefreq>\n'
        sitemap_content += '    <priority>1.0</priority>\n'
        sitemap_content += '  </url>\n'
        
        all_categories = {**categories, **special_categories}
        for main_cat, sub_cats in all_categories.items():
            sitemap_content += '  <url>\n'
            sitemap_content += f'    <loc>{base_url}category/{main_cat.replace(" ", "")}.html</loc>\n'
            sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
            sitemap_content += '    <changefreq>daily</changefreq>\n'
            sitemap_content += '    <priority>0.8</priority>\n'
            sitemap_content += '  </url>\n'
            for sub_cat in sub_cats:
                sitemap_content += '  <url>\n'
                sitemap_content += f'    <loc>{base_url}category/{sub_cat.replace(" ", "")}.html</loc>\n'
                sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
                sitemap_content += '    <changefreq>daily</changefreq>\n'
                sitemap_content += '    <priority>0.7</priority>\n'
                sitemap_content += '  </url>\n'
        
        sitemap_content += '  <url>\n'
        sitemap_content += f'    <loc>{base_url}tags/index.html</loc>\n'
        sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
        sitemap_content += '    <changefreq>daily</changefreq>\n'
        sitemap_content += '    <priority>0.8</priority>\n'
        sitemap_content += '  </url>\n'
        
        for tag in all_tags:
            sitemap_content += '  <url>\n'
            sitemap_content += f'    <loc>{base_url}tags/{tag.replace(" ", "")}.html</loc>\n'
            sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
            sitemap_content += '    <changefreq>daily</changefreq>\n'
            sitemap_content += '    <priority>0.6</priority>\n'
            sitemap_content += '  </url>\n'
        
        for product in products:
            sitemap_content += '  <url>\n'
            sitemap_content += f'    <loc>{base_url}{product.get("page_url", "")}</loc>\n'
            sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
            sitemap_content += '    <changefreq>daily</changefreq>\n'
            sitemap_content += '    <priority>0.6</priority>\n'
            sitemap_content += '  </url>\n'
        
        static_pages = ["privacy.html", "disclaimer.html", "contact.html"]
        for page in static_pages:
            sitemap_content += '  <url>\n'
            sitemap_content += f'    <loc>{base_url}{page}</loc>\n'
            sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
            sitemap_content += '    <changefreq>monthly</changefreq>\n'
            sitemap_content += '    <priority>0.5</priority>\n'
            sitemap_content += '  </url>\n'
        sitemap_content += '</urlset>'
        with open('sitemap.xml', 'w', encoding='utf-8') as f:
            f.write(sitemap_content)
        print("sitemap.xml ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")

    create_sitemap()
    print("ã‚µã‚¤ãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    rakuten_products = fetch_rakuten_items()
    products = update_products_csv(rakuten_products)
    generate_site(products)
