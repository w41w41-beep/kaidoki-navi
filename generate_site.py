import json
import math
import os
import shutil
import time
from datetime import date
import requests

# 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®å•†å“æ•°ã‚’å®šç¾©
PRODUCTS_PER_PAGE = 24

# APIã‚­ãƒ¼ã¯å®Ÿè¡Œç’°å¢ƒãŒè‡ªå‹•çš„ã«ä¾›çµ¦ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ç©ºã®æ–‡å­—åˆ—ã¨ã—ã¾ã™ã€‚
# OpenAI APIã®è¨­å®š
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")  # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
MODEL_NAME = "gpt-4o-mini"

def generate_ai_analysis(product_name, product_price, price_history):
    """
    OpenAI APIã‚’ä½¿ç”¨ã—ã¦ã€å•†å“ã®ä¾¡æ ¼åˆ†æãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
    å¿œç­”ã¯ä¸€è¨€ã‚¢ãƒ”ãƒ¼ãƒ«ã¨è©³ç´°åˆ†æã®2ã¤ã®éƒ¨åˆ†ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹ã€‚
    """
    if not OPENAI_API_KEY:
        print("è­¦å‘Š: OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚AIåˆ†æã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
        return "AIåˆ†ææº–å‚™ä¸­", "è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚"
    
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {OPENAI_API_KEY}'
    }

    # ä¾¡æ ¼å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ 
    history_text = f"éå»ã®ä¾¡æ ¼å±¥æ­´ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™:\n{price_history}" if price_history else "ä¾¡æ ¼å±¥æ­´ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
    
    messages = [
        {"role": "system", "content": "ã‚ãªãŸã¯ã€ä¾¡æ ¼æ¯”è¼ƒã®å°‚é–€å®¶ã¨ã—ã¦ã€æ¶ˆè²»è€…ã«å•†å“ã®è²·ã„æ™‚ã‚’ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã—ã¾ã™ã€‚å›ç­”ã¯å¿…ãšJSONå½¢å¼ã§æä¾›ã—ã¦ãã ã•ã„ã€‚JSONã¯ã€Œheadlineã€ã¨ã€Œanalysisã€ã®2ã¤ã®ã‚­ãƒ¼ã‚’æŒã¡ã¾ã™ã€‚ã€Œheadlineã€ã¯å•†å“ã®è²·ã„æ™‚ã‚’ä¼ãˆã‚‹ç°¡æ½”ãªä¸€è¨€ã§ã€å¯èƒ½ã§ã‚ã‚Œã°å…·ä½“çš„ãªå‰²å¼•ç‡ã‚„æ•°å­—ã‚’ä½¿ã£ã¦è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚ã€Œanalysisã€ã¯ãªãœè²·ã„æ™‚ãªã®ã‹ã‚’èª¬æ˜ã™ã‚‹è©³ç´°ãªæ–‡ç« ã§ã™ã€‚æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"},
        {"role": "user", "content": f"{product_name}ã¨ã„ã†å•†å“ã®ç¾åœ¨ã®ä¾¡æ ¼ã¯{product_price}å††ã§ã™ã€‚{history_text}ã€‚ã“ã®å•†å“ã®ä¾¡æ ¼ã«ã¤ã„ã¦ã€å¸‚å ´ã®å‹•å‘ã‚’è¸ã¾ãˆãŸåˆ†æã¨è²·ã„æ™‚ã«é–¢ã™ã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚"}
    ]
    
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "response_format": {"type": "json_object"},
        "tools": [
            {
                "type": "function",
                "function": {
                    "name": "google_search",
                    "description": "Googleæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ã€æœ€æ–°ã®ä¾¡æ ¼å‹•å‘ã‚„å¸‚å ´æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "queries": {
                                "type": "array",
                                "items": { "type": "string" }
                            }
                        },
                        "required": ["queries"]
                            }
                        }
                    }
                ],
        "tool_choice": "auto"
    }

    try:
        response = requests.post(OPENAI_API_URL, headers=headers, data=json.dumps(payload), timeout=10) # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¿½åŠ 
        response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ã‚’ç¢ºèª
        result = response.json()
        
        # å¿œç­”ã‹ã‚‰JSONãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦ãƒ‘ãƒ¼ã‚¹
        json_text = result.get('choices', [{}])[0].get('message', {}).get('content', '')
        if json_text:
            analysis_data = json.loads(json_text)
            return analysis_data.get('headline', 'AIåˆ†ææº–å‚™ä¸­'), analysis_data.get('analysis', 'è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚')
        
    except requests.exceptions.Timeout:
        print("OpenAI APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
    except requests.exceptions.RequestException as e:
        print(f"OpenAI APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    except (IndexError, KeyError, json.JSONDecodeError) as e:
        print(f"OpenAI APIã®å¿œç­”å½¢å¼ãŒä¸æ­£ã§ã™: {e}")
    
    return "AIåˆ†ææº–å‚™ä¸­", "è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚"

def generate_ai_summary(text):
    """
    ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’AIã«è¦ç´„ã•ã›ã‚‹é–¢æ•°
    """
    if not OPENAI_API_KEY:
        print("è­¦å‘Š: OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å•†å“èª¬æ˜ã®è¦ç´„ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
        return "ã“ã®å•†å“ã®è©³ã—ã„èª¬æ˜ã¯æº–å‚™ä¸­ã§ã™ã€‚æã‚Œå…¥ã‚Šã¾ã™ãŒã€ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
    
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {OPENAI_API_KEY}'
    }

    messages = [
        {"role": "system", "content": "ã‚ãªãŸã¯ã€ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒ—ãƒ­ã®ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰æä¾›ã•ã‚ŒãŸå•†å“èª¬æ˜ã®æ–‡ç« ã‚’èª­ã¿ã€ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã«æ²è¼‰ã™ã‚‹ã®ã«é©ã—ãŸã€ç°¡æ½”ã§é­…åŠ›çš„ãªè¦ç´„ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é©åˆ‡ã«å«ã¿ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³¼å…¥æ„æ¬²ã‚’é«˜ã‚ã‚‹ã‚ˆã†ãªæ–‡ç« ã«ã—ã¦ãã ã•ã„ã€‚å‡ºåŠ›ã¯è¦ç´„ã•ã‚ŒãŸæ–‡ç« ã®ã¿ã«ã—ã¦ãã ã•ã„ã€‚"},
        {"role": "user", "content": f"ä»¥ä¸‹ã®å•†å“èª¬æ˜ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n{text}"}
    ]
    
    payload = {
        "model": MODEL_NAME,
        "messages": messages
    }
    
    try:
        response = requests.post(OPENAI_API_URL, headers=headers, data=json.dumps(payload), timeout=10)
        response.raise_for_status()
        result = response.json()
        
        summary_text = result.get('choices', [{}])[0].get('message', {}).get('content', '')
        if summary_text:
            return summary_text
    
    except requests.exceptions.Timeout:
        print("OpenAI APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
    except requests.exceptions.RequestException as e:
        print(f"OpenAI APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    except (IndexError, KeyError) as e:
        print(f"OpenAI APIã®å¿œç­”å½¢å¼ãŒä¸æ­£ã§ã™: {e}")
    
    return "ã“ã®å•†å“ã®è©³ã—ã„èª¬æ˜ã¯æº–å‚™ä¸­ã§ã™ã€‚æã‚Œå…¥ã‚Šã¾ã™ãŒã€ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"

def generate_ai_subcategory(product_name):
    """
    OpenAI APIã‚’ä½¿ç”¨ã—ã¦ã€å•†å“ã®ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    if not OPENAI_API_KEY:
        print("è­¦å‘Š: OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚AIã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
        return "æœªåˆ†é¡"
    
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {OPENAI_API_KEY}'
    }
    
    messages = [
        {"role": "system", "content": "ã‚ãªãŸã¯å•†å“ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†é¡ã®å°‚é–€å®¶ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸå•†å“åã‹ã‚‰ã€æœ€ã‚‚é©åˆ‡ã§çŸ­ã„ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼åã‚’1ã¤ã ã‘æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚ä¾‹ï¼šã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã‚±ãƒ¼ã‚¹, ãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ã‚¤ãƒ¤ãƒ›ãƒ³, ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³, é›»å‹•æ­¯ãƒ–ãƒ©ã‚·"},
        {"role": "user", "content": f"å•†å“å: {product_name}"}
    ]
    
    payload = {
        "model": MODEL_NAME,
        "messages": messages
    }
    
    try:
        response = requests.post(OPENAI_API_URL, headers=headers, data=json.dumps(payload), timeout=5)
        response.raise_for_status()
        subcategory = response.json()['choices'][0]['message']['content'].strip()
        return subcategory
    except requests.exceptions.RequestException as e:
        print(f"AIã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    except (IndexError, KeyError) as e:
        print(f"AIã®å¿œç­”å½¢å¼ãŒä¸æ­£ã§ã™: {e}")
    
    return "æœªåˆ†é¡"


def fetch_rakuten_items(summary_dict):
    """æ¥½å¤©APIã‹ã‚‰è¤‡æ•°ã®ã‚«ãƒ†ã‚´ãƒªã§å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹é–¢æ•°"""
    app_id = os.environ.get('RAKUTEN_API_KEY')
    if not app_id:
        print("RAKUTEN_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return []

    keywords = ['ãƒ‘ã‚½ã‚³ãƒ³', 'å®¶é›»']
    all_products = []

    for keyword in keywords:
        url = f"https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706?applicationId={app_id}&keyword={keyword}&format=json&sort=-reviewCount&hits=10"

        try:
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()
            items = data.get('Items', [])
            
            for item in items:
                item_data = item['Item']
                item_id = item_data['itemCode']
                
                # è¦ç´„ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                ai_summary = summary_dict.get(item_id, {}).get('ai_summary')
                
                if ai_summary is None:
                    # è¦ç´„ãŒãªã‘ã‚Œã°æ–°ã—ãç”Ÿæˆ
                    description = item_data.get('itemCaption', '')
                    ai_summary = generate_ai_summary(description) if description else "ã“ã®å•†å“ã®è©³ã—ã„èª¬æ˜ã¯æº–å‚™ä¸­ã§ã™ã€‚æã‚Œå…¥ã‚Šã¾ã™ãŒã€ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"

                # ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’AIã§ç”Ÿæˆ
                ai_subcategory = generate_ai_subcategory(item_data['itemName'])

                all_products.append({
                    "id": item_id,
                    "name": item_data['itemName'],
                    "price": f"{int(item_data['itemPrice']):,}",
                    "image_url": item_data['mediumImageUrls'][0]['imageUrl'],
                    "rakuten_url": item_data['itemUrl'],
                    "yahoo_url": "https://shopping.yahoo.co.jp/", 
                    "amazon_url": "https://www.amazon.co.jp/ref=as_li_ss_il?ie=UTF8&linkCode=ilc&tag=soc07-22&linkId=db3c1808e6f1f516353d266e76811a7c&language=ja_JP",
                    "page_url": f"pages/{item_id}.html",
                    "category": {
                        "main": keyword,
                        "sub": ai_subcategory
                    },
                    "ai_headline": "AIåˆ†ææº–å‚™ä¸­",
                    "ai_analysis": "è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚",
                    "description": item_data.get('itemCaption', ''),
                    "ai_summary": ai_summary,
                    "date": date.today().isoformat(),
                    "main_ec_site": "æ¥½å¤©",
                    "price_history": []
                })
        except requests.exceptions.RequestException as e:
            print(f"æ¥½å¤©APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            
    return all_products

def fetch_yahoo_items(summary_dict):
    """Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°APIã‹ã‚‰å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹é–¢æ•°"""
    app_id = os.environ.get('YAHOO_API_KEY')
    if not app_id:
        print("YAHOO_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return []

    keywords = ['æƒé™¤æ©Ÿ', 'ã‚¤ãƒ¤ãƒ›ãƒ³']
    all_products = []
    
    for keyword in keywords:
        url = f"https://shopping.yahooapis.jp/ShoppingWebService/V3/itemSearch?appid={app_id}&query={keyword}&sort=-review_count&hits=5"
        
        try:
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()
            items = data.get('hits', [])
            
            for item in items:
                item_id = item['jan_code']
                
                # è¦ç´„ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                ai_summary = summary_dict.get(item_id, {}).get('ai_summary')
                
                if ai_summary is None:
                    # è¦ç´„ãŒãªã‘ã‚Œã°æ–°ã—ãç”Ÿæˆ
                    description = item.get('description', '')
                    ai_summary = generate_ai_summary(description) if description else "ã“ã®å•†å“ã®è©³ã—ã„èª¬æ˜ã¯æº–å‚™ä¸­ã§ã™ã€‚æã‚Œå…¥ã‚Šã¾ã™ãŒã€ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
                
                # ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’AIã§ç”Ÿæˆ
                ai_subcategory = generate_ai_subcategory(item['name'])

                all_products.append({
                    "id": item_id,
                    "name": item['name'],
                    "price": f"{int(item['price']):,}",
                    "image_url": item['image']['medium'],
                    "rakuten_url": "https://www.rakuten.co.jp/",
                    "yahoo_url": item['url'],
                    "amazon_url": "https://www.amazon.co.jp/ref=as_li_ss_il?ie=UTF8&linkCode=ilc&tag=soc07-22&linkId=db3c1808e6f1f516353d266e76811a7c&language=ja_JP",
                    "page_url": f"pages/{item_id}.html",
                    "category": {
                        "main": keyword,
                        "sub": ai_subcategory
                    },
                    "ai_headline": "AIåˆ†ææº–å‚™ä¸­",
                    "ai_analysis": "è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚",
                    "description": item.get('description', ''),
                    "ai_summary": ai_summary,
                    "date": date.today().isoformat(),
                    "main_ec_site": "Yahoo!",
                    "price_history": []
                })
        except requests.exceptions.RequestException as e:
            print(f"Yahoo! APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            
    return all_products

def update_products_json(new_products):
    """
    æ–°ã—ã„å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æ—¢å­˜ã®products.jsonã«çµ±åˆãƒ»æ›´æ–°ã™ã‚‹é–¢æ•°ã€‚
    ã“ã®é–¢æ•°å†…ã§AIåˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    """
    try:
        if os.path.exists('products.json'):
            with open('products.json', 'r', encoding='utf-8') as f:
                existing_products = json.load(f)
        else:
            existing_products = []
    except json.JSONDecodeError:
        print("products.jsonãŒç ´æã—ã¦ã„ã‚‹ãŸã‚ã€æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
        existing_products = []

    updated_products = {p['id']: p for p in existing_products}
    for new_product in new_products:
        if new_product['id'] in updated_products:
            existing_product = updated_products[new_product['id']]
            if 'price_history' not in existing_product:
                existing_product['price_history'] = []
            
            current_date = date.today().isoformat()
            try:
                current_price = int(new_product['price'].replace(',', ''))
                if not existing_product['price_history'] or existing_product['price_history'][-1]['date'] != current_date:
                    existing_product['price_history'].append({"date": current_date, "price": current_price})
            except ValueError:
                print(f"ä¾¡æ ¼ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {new_product['price']}")

            existing_product.update(new_product)
        else:
            try:
                new_product['price_history'] = [{"date": date.today().isoformat(), "price": int(new_product['price'].replace(',', ''))}]
                updated_products[new_product['id']] = new_product
            except ValueError:
                print(f"ä¾¡æ ¼ã®å¤‰æ›ã«å¤±æ•—ã—ãŸãŸã‚ã€å•†å“ {new_product['id']} ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
    
    final_products = list(updated_products.values())
    
    print("AIã«ã‚ˆã‚‹ä¾¡æ ¼åˆ†æã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    for i, product in enumerate(final_products):
        print(f"å•†å“ {i+1}/{len(final_products)}: '{product['name']}' ã®AIåˆ†æã‚’ç”Ÿæˆä¸­...")
        try:
            price_int = int(product['price'].replace(',', ''))
            price_history = product.get('price_history', [])
            ai_headline, ai_analysis_text = generate_ai_analysis(product['name'], price_int, price_history)
            product['ai_headline'] = ai_headline
            product['ai_analysis'] = ai_analysis_text
            time.sleep(1)
        except ValueError:
            print(f"ä¾¡æ ¼ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {product['price']}")
            product['ai_headline'] = "AIåˆ†ææº–å‚™ä¸­"
            product['ai_analysis'] = "è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚"

    print("AIã«ã‚ˆã‚‹ä¾¡æ ¼åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    
    with open('products.json', 'w', encoding='utf-8') as f:
        json.dump(final_products, f, ensure_ascii=False, indent=4)
    
    print(f"products.jsonãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸã€‚ç¾åœ¨ {len(final_products)} å€‹ã®å•†å“ã‚’è¿½è·¡ä¸­ã§ã™ã€‚")
    return final_products


def generate_site(products):
    """products.jsonã‚’èª­ã¿è¾¼ã¿ã€HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
    today = date.today().isoformat()
    for product in products:
        if 'date' not in product:
            product['date'] = today
    products.sort(key=lambda p: p['date'], reverse=True)
    categories = {}
    for product in products:
        main_cat = product['category']['main']
        sub_cat = product['category']['sub']
        if main_cat not in categories:
            categories[main_cat] = []
        if sub_cat and sub_cat not in categories[main_cat]:
            categories[main_cat].append(sub_cat)
    sorted_main_cats = sorted(categories.keys())

    def generate_header_footer(current_path, sub_cat_links=None, page_title="ãŠå¾—ãªè²·ã„æ™‚ã‚’è¦‹ã¤ã‘ã‚ˆã†ï¼"):
        if "pages" in current_path:
            base_path = ".."
        elif "category" in current_path:
            base_path = "../.."
        elif "tags" in current_path:
            base_path = ".."
        else:
            base_path = "."
        main_links_html = f'<a href="{base_path}/tags/index.html">ã‚¿ã‚°ã‹ã‚‰æ¢ã™</a><span class="separator">|</span>'
        for mc_link in sorted_main_cats:
            main_links_html += f'<a href="{base_path}/category/{mc_link}/index.html">{mc_link}</a><span class="separator">|</span>'
        header_html = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“ | {page_title}</title>
    <link rel="stylesheet" href="{base_path}/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <meta name="google-site-verification" content="OmUuOjcxi7HXBKe47sd0WPbzCfbCOFbPj_iueHBk2qo" />
</head>
<body>
    <header>
        <div class="container">
            <h1><a href="{base_path}/index.html">ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“</a></h1>
            <p>ãŠå¾—ãªè²·ã„æ™‚ã‚’è¦‹ã¤ã‘ã‚ˆã†ï¼</p>
        </div>
    </header>

    <div class="search-bar">
        <div class="search-container">
            <input type="text" placeholder="å•†å“åã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢...">
            <button class="search-button">ğŸ”</button>
        </div>
    </div>

    <div class="genre-links-container">
        <div class="genre-links">
            {main_links_html}
        </div>
    </div>
"""
        sub_cat_links_html = ""
        if sub_cat_links:
            sub_cat_links_html += '<div class="genre-links sub-genre-links">'
            for sub_cat_link in sorted(sub_cat_links):
                # ãƒ•ã‚¡ã‚¤ãƒ«åã¨ã—ã¦ç„¡åŠ¹ãªæ–‡å­—ã‚’å‰Šé™¤ãƒ»ç½®æ›
                safe_sub_cat = sub_cat_link.replace(' ', '').replace('/', '').replace('\\', '')
                if safe_sub_cat:  # ãƒ•ã‚¡ã‚¤ãƒ«åãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
                    sub_cat_links_html += f'<a href="{safe_sub_cat}.html">{sub_cat_link}</a><span class="separator">|</span>'
            sub_cat_links_html += '</div>'
            header_html += f"""
    <div class="sub-genre-links-container">
        {sub_cat_links_html}
    </div>
"""
        footer_html = f"""
    </main>
    <footer>
        <p>&copy; 2025 ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“. All Rights Reserved.</p>
        <div class="footer-links">
            <a href="{base_path}/privacy.html">ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼</a>
            <a href="{base_path}/disclaimer.html">å…è²¬äº‹é …</a>
            <a href="{base_path}/contact.html">ãŠå•ã„åˆã‚ã›</a>
        </div>
    </footer>
    <script src="{base_path}/script.js"></script>
</body>
</html>
        """
        return header_html, footer_html

    # å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    for root, dirs, files in os.walk('.'):
        for file in files:
            if file.endswith('.html') and not file in ['privacy.html', 'disclaimer.html', 'contact.html', 'sitemap.xml']:
                os.remove(os.path.join(root, file))
    if os.path.exists('category'):
        shutil.rmtree('category')
    if os.path.exists('pages'):
        shutil.rmtree('pages')
    if os.path.exists('tags'):
        shutil.rmtree('tags')

    for main_cat, sub_cats in categories.items():
        main_cat_products = [p for p in products if p['category']['main'] == main_cat]
        page_path = f"category/{main_cat}/index.html"
        os.makedirs(os.path.dirname(page_path), exist_ok=True)
        header, footer = generate_header_footer(page_path, sub_cat_links=sub_cats, page_title=f"{main_cat}ã®å•†å“ä¸€è¦§")
        main_content_html = f"""
 <main class="container">
 <div class="ai-recommendation-section">
 <h2 class="ai-section-title">{main_cat}ã®å•†å“ä¸€è¦§</h2>
 <div class="product-grid">
 """
        products_html = ""
        for product in main_cat_products:
            link_path = os.path.relpath(product['page_url'], os.path.dirname(page_path))
            products_html += f"""
 <a href="{link_path}" class="product-card">
 <img src="{product['image_url']}" alt="{product['name']}">
 <div class="product-info">
 <h3 class="product-name">{product['name'][:20] + '...' if len(product['name']) > 20 else product['name']}</h3>
 <p class="product-price">{product['price']}å††</p>
 <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
 <div class="price-status-content ai-analysis">{product['ai_headline']}</div>
 </div>
 </a>
 """
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + main_content_html + products_html + "</div>" + footer)
        print(f"category/{main_cat}/index.html ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
        for sub_cat in sub_cats:
            sub_cat_products = [p for p in products if p['category']['sub'] == sub_cat]
            
            # --- ã“ã“ãŒä¿®æ­£ç‚¹ã§ã™ ---
            # ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªåãŒç©ºã¾ãŸã¯ä¸é©åˆ‡ãªå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            safe_sub_cat = sub_cat.replace(' ', '').replace('/', '').replace('\\', '')
            if not safe_sub_cat:
                print(f"è­¦å‘Š: ä¸æ­£ãªã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªå '{sub_cat}' ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
                continue

            sub_cat_file_name = f"{safe_sub_cat}.html"
            page_path = f"category/{main_cat}/{sub_cat_file_name}"
            os.makedirs(os.path.dirname(page_path), exist_ok=True)
            header, footer = generate_header_footer(page_path, page_title=f"{sub_cat}ã®å•†å“ä¸€è¦§")
            main_content_html = f"""
 <main class="container">
 <div class="ai-recommendation-section">
 <h2 class="ai-section-title">{sub_cat}ã®å•†å“ä¸€è¦§</h2>
 <div class="product-grid">
 """
            products_html = ""
            for product in sub_cat_products:
                link_path = os.path.relpath(product['page_url'], os.path.dirname(page_path))
                products_html += f"""
 <a href="{link_path}" class="product-card">
 <img src="{product['image_url']}" alt="{product['name']}">
 <div class="product-info">
 <h3 class="product-name">{product['name'][:20] + '...' if len(product['name']) > 20 else product['name']}</h3>
 <p class="product-price">{product['price']}å††</p>
 <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
 <div class="price-status-content ai-analysis">{product['ai_headline']}</div>
 </div>
 </a>
 """
            with open(page_path, 'w', encoding='utf-8') as f:
                f.write(header + main_content_html + products_html + "</div>" + footer)
            print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    total_pages = math.ceil(len(products) / PRODUCTS_PER_PAGE)
    for i in range(total_pages):
        start_index = i * PRODUCTS_PER_PAGE
        end_index = start_index + PRODUCTS_PER_PAGE
        paginated_products = products[start_index:end_index]
        page_num = i + 1
        page_path = f"index.html" if page_num == 1 else f"page/{page_num}.html"
        os.makedirs(os.path.dirname(page_path), exist_ok=True)
        header, footer = generate_header_footer(page_path, page_title=f"å•†å“ä¸€è¦§ï¼ˆ{page_num}ãƒšãƒ¼ã‚¸ç›®ï¼‰")
        
        pagination_html = '<div class="pagination-buttons">'
        if page_num > 1:
            prev_page_url = f"index.html" if page_num == 2 else f"page/{page_num - 1}.html"
            pagination_html += f'<a href="{prev_page_url}" class="pagination-button">å‰ã®ãƒšãƒ¼ã‚¸</a>'
        if page_num < total_pages:
            next_page_url = f"page/{page_num + 1}.html"
            pagination_html += f'<a href="{next_page_url}" class="pagination-button">æ¬¡ã®ãƒšãƒ¼ã‚¸</a>'
        pagination_html += '</div>'
        
        main_content_html = f"""
<main class="container">
 <div class="ai-recommendation-section">
 <h2 class="ai-section-title">AIãŠã™ã™ã‚å•†å“</h2>
 <div class="product-grid">
 """
        products_html = ""
        for product in paginated_products:
            link_path = os.path.relpath(product['page_url'], os.path.dirname(page_path))
            products_html += f"""
 <a href="{link_path}" class="product-card">
 <img src="{product['image_url']}" alt="{product['name']}">
 <div class="product-info">
 <h3 class="product-name">{product['name'][:20] + '...' if len(product['name']) > 20 else product['name']}</h3>
 <p class="product-price">{product['price']}å††</p>
 <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
 <div class="price-status-content ai-analysis">{product['ai_headline']}</div>
 </div>
 </a>
 """
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + main_content_html + products_html + "</div>" + pagination_html + footer)
        print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")

    os.makedirs('pages', exist_ok=True)
    for product in products:
        page_path = f"pages/{product['id']}.html"
        header, footer = generate_header_footer(page_path, page_title=product['name'])
        
        price_history_html = ""
        if product['price_history']:
            price_history_html = """
<div class="product-detail-section">
<h3>ä¾¡æ ¼å±¥æ­´</h3>
<div class="price-history-chart">
<canvas id="priceChart"></canvas>
</div>
</div>
"""
        
        affiliate_links_html = ""
        if 'affiliateLinks' in product:
            for link in product['affiliateLinks']:
                affiliate_links_html += f'<li><a href="{link["url"]}" target="_blank" rel="noopener noreferrer">{link["shop"]}ã§è©³ç´°ã‚’è¦‹ã‚‹</a></li>'
        else:
            # å­˜åœ¨ã—ãªã„å ´åˆã®ãŸã‚ã«ã€ãƒ€ãƒŸãƒ¼ã®ãƒªãƒ³ã‚¯ã‚’è¿½åŠ 
            affiliate_links_html = f"""
<li><a href="{product['rakuten_url']}" target="_blank" rel="noopener noreferrer">æ¥½å¤©å¸‚å ´ã§è©³ç´°ã‚’è¦‹ã‚‹</a></li>
<li><a href="{product['yahoo_url']}" target="_blank" rel="noopener noreferrer">Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã§è©³ç´°ã‚’è¦‹ã‚‹</a></li>
<li><a href="{product['amazon_url']}" target="_blank" rel="noopener noreferrer">Amazonã§è©³ç´°ã‚’è¦‹ã‚‹</a></li>
"""


        main_content_html = f"""
<main class="container product-detail">
 <div class="product-detail-header">
 <img src="{product['image_url']}" alt="{product['name']}" class="product-image">
 <h2>{product['name']}</h2>
 </div>
 <div class="product-detail-section">
 <h3>AIã«ã‚ˆã‚‹å•†å“ãƒã‚¤ãƒ©ã‚¤ãƒˆ</h3>
 <p>{product.get('ai_summary', '')}</p>
 </div>
 <div class="product-detail-section">
 <h3>AIä¾¡æ ¼åˆ†æ</h3>
 <h4>{product['ai_headline']}</h4>
 <p>{product['ai_analysis']}</p>
 </div>
 <div class="product-detail-section">
 <h3>å•†å“èª¬æ˜</h3>
 <p>{product['description']}</p>
 </div>
 <div class="product-detail-section">
 <h3>è³¼å…¥ã¯ã“ã¡ã‚‰ã‹ã‚‰</h3>
 <ul class="affiliate-links">
 {affiliate_links_html}
 </ul>
 </div>
 {price_history_html}
</main>
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<script>
 const priceData = {json.dumps(product['price_history'])};
 if (priceData.length > 0) {{
 const labels = priceData.map(d => d.date);
 const data = priceData.map(d => d.price);
 const ctx = document.getElementById('priceChart').getContext('2d');
 new Chart(ctx, {{
 type: 'line',
 data: {{
 labels: labels,
 datasets: [{{
 label: 'ä¾¡æ ¼ (å††)',
 data: data,
 borderColor: 'rgb(75, 192, 192)',
 tension: 0.1
 }}]
 }},
 options: {{
 responsive: true,
 maintainAspectRatio: false,
 scales: {{
 x: {{
 title: {{
 display: true,
 text: 'æ—¥ä»˜'
 }}
 }},
 y: {{
 title: {{
 display: true,
 text: 'ä¾¡æ ¼ (å††)'
 }}
 }}
 }}
 }}
 }});
 }}
</script>
        """
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + main_content_html + footer)
        print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    # é™çš„ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°å‘¼ã³å‡ºã—ã‚’å‰Šé™¤
    # generate_static_page('privacy.html', 'ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼', '<main class="container"><div class="static-content"><h2>ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼</h2><p>å½“ã‚µã‚¤ãƒˆã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å€‹äººæƒ…å ±ã®ä¿è­·ã«æœ€å¤§é™ã®æ³¨æ„ã‚’æ‰•ã£ã¦ã„ã¾ã™ã€‚...</p></div>')
    # generate_static_page('disclaimer.html', 'å…è²¬äº‹é …', '<main class="container"><div class="static-content"><h2>å…è²¬äº‹é …</h2><p>å½“ã‚µã‚¤ãƒˆã§æä¾›ã•ã‚Œã‚‹æƒ…å ±ã‚„ä¾¡æ ¼ã¯ã€æ²è¼‰æ™‚ç‚¹ã®ã‚‚ã®ã§ã‚ã‚Šã€ãã®æ­£ç¢ºæ€§ã‚„å®Œå…¨æ€§ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚...</p></div>')
    # generate_static_page('contact.html', 'ãŠå•ã„åˆã‚ã›', '<main class="container"><div class="static-content"><h2>ãŠå•ã„åˆã‚ã›</h2><p>å½“ã‚µã‚¤ãƒˆã«é–¢ã™ã‚‹ãŠå•ã„åˆã‚ã›ã¯ã€ä»¥ä¸‹ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¾ã§ãŠé¡˜ã„ã„ãŸã—ã¾ã™ã€‚...</p></div>')

def create_sitemap(products):
    """
    å•†å“ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰sitemap.xmlã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°ã€‚
    """
    base_url = "https://your-domain.com/"
    sitemap_content = '<?xml version="1.0" encoding="UTF-8"?>\n'
    sitemap_content += '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'
    sitemap_content += '  <url>\n'
    sitemap_content += f'    <loc>{base_url}</loc>\n'
    sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
    sitemap_content += '    <changefreq>daily</changefreq>\n'
    sitemap_content += '    <priority>1.0</priority>\n'
    sitemap_content += '  </url>\n'
    genres = ['ãƒ‘ã‚½ã‚³ãƒ³', 'å®¶é›»', 'æƒé™¤æ©Ÿ', 'ã‚¤ãƒ¤ãƒ›ãƒ³']
    for genre in genres:
        genre_url = f"{base_url}category/{genre}/"
        sitemap_content += '  <url>\n'
        sitemap_content += f'    <loc>{genre_url}</loc>\n'
        sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
        sitemap_content += '    <changefreq>daily</changefreq>\n'
        sitemap_content += '    <priority>0.8</priority>\n'
        sitemap_content += '  </url>\n'
    total_pages = math.ceil(len(products) / PRODUCTS_PER_PAGE)
    for i in range(1, total_pages + 1):
        page_url = f"page/{i}.html" if i > 1 else ""
        sitemap_content += '  <url>\n'
        sitemap_content += f'    <loc>{base_url}{page_url}</loc>\n'
        sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
        sitemap_content += '    <changefreq>daily</changefreq>\n'
        sitemap_content += '    <priority>0.7</priority>\n'
        sitemap_content += '  </url>\n'
    for product in products:
        sitemap_content += '  <url>\n'
        sitemap_content += f'    <loc>{base_url}{product["page_url"]}</loc>\n'
        sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
        sitemap_content += '    <changefreq>daily</changefreq>\n'
        sitemap_content += '    <priority>0.6</priority>\n'
        sitemap_content += '  </url>\n'
    # é™çš„ãƒšãƒ¼ã‚¸ã®sitemapç”Ÿæˆã‚’å‰Šé™¤
    # static_pages = ["privacy.html", "disclaimer.html", "contact.html"]
    # for page in static_pages:
    #     sitemap_content += '  <url>\n'
    #     sitemap_content += f'    <loc>{base_url}{page}</loc>\n'
    #     sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
    #     sitemap_content += '    <changefreq>monthly</changefreq>\n'
    #     sitemap_content += '    <priority>0.5</priority>\n'
    #     sitemap_content += '  </url>\n'
    sitemap_content += '</urlset>'
    with open('sitemap.xml', 'w', encoding='utf-8') as f:
        f.write(sitemap_content)
    print("sitemap.xml ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")


def main():
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    print("ã‚µã‚¤ãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™...")

    if not OPENAI_API_KEY:
        print("è­¦å‘Š: OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚AIè¦ç´„ã¨AIåˆ†æã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã€‚")
    
    # ai_summaries.jsonãŒå­˜åœ¨ã™ã‚Œã°èª­ã¿è¾¼ã‚€
    try:
        if os.path.exists('ai_summaries.json'):
            with open('ai_summaries.json', 'r', encoding='utf-8') as f:
                summary_dict = json.load(f)
        else:
            summary_dict = {}
    except json.JSONDecodeError:
        print("ai_summaries.jsonãŒç ´æã—ã¦ã„ã‚‹ãŸã‚ã€æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
        summary_dict = {}
    
    # å„ECã‚µã‚¤ãƒˆã‹ã‚‰å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    rakuten_products = fetch_rakuten_items(summary_dict)
    yahoo_products = fetch_yahoo_items(summary_dict)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
    all_products = rakuten_products + yahoo_products
    
    # æ–°ã—ãç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã‚’summary_dictã«è¿½åŠ 
    newly_generated_summaries = {}
    for p in all_products:
        item_id = p.get('id')
        ai_summary = p.get('ai_summary')
        if ai_summary and summary_dict.get(item_id, {}).get('ai_summary') is None:
            newly_generated_summaries[item_id] = {'ai_summary': ai_summary}

    summary_dict.update(newly_generated_summaries)
    
    # æ›´æ–°ã•ã‚ŒãŸè¦ç´„ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open('ai_summaries.json', 'w', encoding='utf-8') as f:
        json.dump(summary_dict, f, ensure_ascii=False, indent=4)
        print(f"ai_summaries.json ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸã€‚")

    # å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’products.jsonã«çµ±åˆãƒ»æ›´æ–°ã—ã€AIåˆ†æã‚’å®Ÿè¡Œ
    final_products = update_products_json(all_products)
    
    # ã‚µã‚¤ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
    generate_site(final_products)
    
    # sitemap.xmlã‚’ç”Ÿæˆ
    create_sitemap(final_products)

    print("ã‚µã‚¤ãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()
