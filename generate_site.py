import json
import math
import os
import shutil
import time
from datetime import date
import requests
import csv

# 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®å•†å“æ•°ã‚’å®šç¾©
PRODUCTS_PER_PAGE = 24

# APIã‚­ãƒ¼ã¯å®Ÿè¡Œç’°å¢ƒãŒè‡ªå‹•çš„ã«ä¾›çµ¦ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ç©ºã®æ–‡å­—åˆ—ã¨ã—ã¾ã™ã€‚
# OpenAI APIã®è¨­å®š
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY") # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
MODEL_NAME = "gpt-4o-mini"
CACHE_FILE = 'products.csv'

def get_cached_data():
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå•†å“ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    cached_data = {}
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                # KeyErrorã‚’é¿ã‘ã‚‹ãŸã‚ã€get()ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
                price_history_str = row.get('price_history', '[]')
                tags_str = row.get('tags', '[]')
                
                row['price_history'] = json.loads(price_history_str.replace("'", '"'))
                row['tags'] = json.loads(tags_str.replace("'", '"'))
                cached_data[row['id']] = row
    return cached_data

def save_to_cache(products):
    """å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹"""
    if not products:
        return
    fieldnames = list(products[0].keys())
    # æ—¢å­˜ã®CSVã«ãªã„æ–°ã—ã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã‚’è¿½åŠ 
    existing_fieldnames = []
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            existing_fieldnames = reader.fieldnames
    
    # æ–°ã—ã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åãŒå­˜åœ¨ã™ã‚‹å ´åˆã€æ—¢å­˜ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã«ãƒãƒ¼ã‚¸
    for key in fieldnames:
        if key not in existing_fieldnames:
            existing_fieldnames.append(key)
            
    with open(CACHE_FILE, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=existing_fieldnames)
        writer.writeheader()
        for product in products:
            # ãƒªã‚¹ãƒˆã‚„è¾æ›¸ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦ä¿å­˜
            product_to_write = product.copy()
            product_to_write['price_history'] = json.dumps(product_to_write.get('price_history', []), ensure_ascii=False)
            product_to_write['tags'] = json.dumps(product_to_write.get('tags', []), ensure_ascii=False)
            writer.writerow(product_to_write)

def generate_ai_metadata(product_name, product_description):
    """
    OpenAI APIã‚’ä½¿ç”¨ã—ã¦ã€å•†å“ã®è¦ç´„ã€ã‚¿ã‚°ã€ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    if not OPENAI_API_KEY:
        print("è­¦å‘Š: OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚AIãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
        return "", [], ""
    
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {OPENAI_API_KEY}'
    }

    prompt = f"""
    ä»¥ä¸‹ã®å•†å“æƒ…å ±ã‚’ã‚‚ã¨ã«ã€ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ã—ã¦æœ€é©ãªã€ç°¡æ½”ã§é­…åŠ›çš„ãªè¦ç´„ã€é–¢é€£ã™ã‚‹ã‚¿ã‚°ï¼ˆ3ã€œ5å€‹ï¼‰ã€ãã—ã¦é©åˆ‡ãªã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆ1ã¤ï¼‰ã‚’æ—¥æœ¬èªã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
    å›ç­”ã¯å¿…ãšJSONå½¢å¼ã§æä¾›ã—ã¦ãã ã•ã„ã€‚JSONã¯ã€Œsummaryã€ã€ã€Œtagsã€ã€ã€Œsub_categoryã€ã®3ã¤ã®ã‚­ãƒ¼ã‚’æŒã¡ã¾ã™ã€‚

    å•†å“å: {product_name}
    å•†å“èª¬æ˜: {product_description}

    è¦ç´„ã®æ–‡ç« ã«ã¯ã€SEOã‚’æ„è­˜ã—ãŸã€Œæ ¼å®‰ã€ã€Œæœ€å®‰å€¤ã€ã€Œã‚»ãƒ¼ãƒ«ã€ã€Œå‰²å¼•ã€ãªã©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªç„¶ã«å«ã‚ã¦ãã ã•ã„ã€‚
    ã‚¿ã‚°ã¯å•†å“ã®ç‰¹å¾´ã‚„ç”¨é€”ã‚’è¡¨ã™å˜èªã‚’ãƒªã‚¹ãƒˆå½¢å¼ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
    ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¯ã€å•†å“ã®ã‚¸ãƒ£ãƒ³ãƒ«ã‚’ç´°åˆ†åŒ–ã—ãŸå˜ä¸€ã®å˜èªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
    """
    
    messages = [
        {"role": "system", "content": "ã‚ãªãŸã¯ã€ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒ—ãƒ­ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æŒ‡ç¤ºã«å¾“ã„ã€å•†å“æƒ…å ±ã‚’åˆ†æã—ã¦é­…åŠ›çš„ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã—ã¾ã™ã€‚"},
        {"role": "user", "content": prompt}
    ]
    
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "response_format": {"type": "json_object"}
    }
    
    try:
        response = requests.post(OPENAI_API_URL, headers=headers, data=json.dumps(payload), timeout=15)
        response.raise_for_status()
        result = response.json()
        
        json_text = result.get('choices', [{}])[0].get('message', {}).get('content', '')
        if json_text:
            metadata = json.loads(json_text)
            summary = metadata.get('summary', "ã“ã®å•†å“ã®è©³ã—ã„èª¬æ˜ã¯æº–å‚™ä¸­ã§ã™ã€‚")
            tags = metadata.get('tags', [])
            sub_category = metadata.get('sub_category', "")
            return summary, tags, sub_category
            
    except requests.exceptions.Timeout:
        print("OpenAI APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
    except requests.exceptions.RequestException as e:
        print(f"OpenAI APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    except (IndexError, KeyError, json.JSONDecodeError) as e:
        print(f"OpenAI APIã®å¿œç­”å½¢å¼ãŒä¸æ­£ã§ã™: {e}")
        
    return "ã“ã®å•†å“ã®è©³ã—ã„èª¬æ˜ã¯æº–å‚™ä¸­ã§ã™ã€‚", [], ""

def generate_ai_analysis(product_name, product_price, price_history):
    """
    OpenAI APIã‚’ä½¿ç”¨ã—ã¦ã€å•†å“ã®ä¾¡æ ¼åˆ†æãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    if not OPENAI_API_KEY:
        print("è­¦å‘Š: OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚AIåˆ†æã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
        return "AIåˆ†ææº–å‚™ä¸­", "è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚"
    
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {OPENAI_API_KEY}'
    }

    history_text = f"éå»ã®ä¾¡æ ¼å±¥æ­´ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™: {price_history}" if price_history else "ä¾¡æ ¼å±¥æ­´ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
    
    messages = [
        {"role": "system", "content": "ã‚ãªãŸã¯ã€ä¾¡æ ¼æ¯”è¼ƒã®å°‚é–€å®¶ã¨ã—ã¦ã€æ¶ˆè²»è€…ã«å•†å“ã®è²·ã„æ™‚ã‚’ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã—ã¾ã™ã€‚å›ç­”ã¯å¿…ãšJSONå½¢å¼ã§æä¾›ã—ã¦ãã ã•ã„ã€‚JSONã¯ã€Œheadlineã€ã¨ã€Œanalysisã€ã®2ã¤ã®ã‚­ãƒ¼ã‚’æŒã¡ã¾ã™ã€‚ã€Œheadlineã€ã¯å•†å“ã®è²·ã„æ™‚ã‚’ä¼ãˆã‚‹ç°¡æ½”ãªä¸€è¨€ã§ã€å¯èƒ½ã§ã‚ã‚Œã°å…·ä½“çš„ãªå‰²å¼•ç‡ã‚„æ•°å­—ã‚’ä½¿ã£ã¦è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚ã€Œanalysisã€ã¯ãªãœè²·ã„æ™‚ãªã®ã‹ã‚’èª¬æ˜ã™ã‚‹è©³ç´°ãªæ–‡ç« ã§ã™ã€‚æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"},
        {"role": "user", "content": f"{product_name}ã¨ã„ã†å•†å“ã®ç¾åœ¨ã®ä¾¡æ ¼ã¯{product_price}å††ã§ã™ã€‚{history_text}ã€‚ã“ã®å•†å“ã®ä¾¡æ ¼ã«ã¤ã„ã¦ã€å¸‚å ´ã®å‹•å‘ã‚’è¸ã¾ãˆãŸåˆ†æã¨è²·ã„æ™‚ã«é–¢ã™ã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚ç‰¹ã«ä¾¡æ ¼ãŒå‰å›ã¨æ¯”ã¹ã¦ä¸‹ãŒã£ã¦ã„ã‚‹å ´åˆã¯ã€**ã€Œæœ€å®‰å€¤ã€**ã‚„**ã€Œã‚»ãƒ¼ãƒ«ã€**ã¨ã„ã£ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ã£ã¦è²·ã„æ™‚ã‚’å¼·èª¿ã—ã¦ãã ã•ã„ã€‚"}
    ]
    
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "response_format": {"type": "json_object"}
    }
    
    try:
        response = requests.post(OPENAI_API_URL, headers=headers, data=json.dumps(payload), timeout=10)
        response.raise_for_status()
        result = response.json()
        
        json_text = result.get('choices', [{}])[0].get('message', {}).get('content', '')
        if json_text:
            analysis_data = json.loads(json_text)
            return analysis_data.get('headline', 'AIåˆ†ææº–å‚™ä¸­'), analysis_data.get('analysis', 'è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚')
            
    except requests.exceptions.Timeout:
        print("OpenAI APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
    except requests.exceptions.RequestException as e:
        print(f"OpenAI APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    except (IndexError, KeyError, json.JSONDecodeError) as e:
        print(f"OpenAI APIã®å¿œç­”å½¢å¼ãŒä¸æ­£ã§ã™: {e}")
        
    return "AIåˆ†ææº–å‚™ä¸­", "è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚"

def fetch_rakuten_items():
    """æ¥½å¤©APIã‹ã‚‰1ä»¶ã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹é–¢æ•°"""
    app_id = os.environ.get('RAKUTEN_API_KEY')
    if not app_id:
        print("RAKUTEN_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return []

    # è²·ã„æ™‚ã‚’åˆ¤æ–­ã—ã‚„ã™ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å„ªå…ˆçš„ã«æ¤œç´¢
    keywords = ['æœ€å®‰å€¤', 'å‰²å¼•', 'ã‚»ãƒ¼ãƒ«', 'ãŠå¾—ãªå•†å“', 'è¨³ã‚ã‚Š']
    all_products = []

    for keyword in keywords:
        url = f"https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706?applicationId={app_id}&keyword={keyword}&format=json&sort=-reviewCount&hits=1"
        try:
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()
            items = data.get('Items', [])
            
            if items:
                item_data = items[0]['Item']
                description = item_data.get('itemCaption', '')
                
                # æ–°ã—ã„å•†å“æƒ…å ±ã‚’æ§‹ç¯‰
                new_product = {
                    "id": item_data['itemCode'],
                    "name": item_data['itemName'],
                    "price": str(item_data['itemPrice']),
                    "image_url": item_data['mediumImageUrls'][0]['imageUrl'],
                    "rakuten_url": item_data['itemUrl'],
                    "yahoo_url": "https://shopping.yahoo.co.jp/search?p=" + item_data['itemName'], # Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°æ¤œç´¢ãƒªãƒ³ã‚¯ã‚’å¾©æ´»
                    "amazon_url": "https://www.amazon.co.jp/ref=as_li_ss_il?ie=UTF8&linkCode=ilc&tag=soc07-22&linkId=db3c1808e6f1f516353d266e76811a7c&language=ja_JP",
                    "page_url": f"pages/{item_data['itemCode']}.html",
                    "category": {"main": keyword, "sub": ""},
                    "ai_headline": "AIåˆ†ææº–å‚™ä¸­",
                    "ai_analysis": "è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚",
                    "description": description,
                    "ai_summary": "",
                    "tags": [],
                    "date": date.today().isoformat(),
                    "main_ec_site": "æ¥½å¤©",
                    "price_history": []
                }
                all_products.append(new_product)
                break # 1ã¤è¦‹ã¤ã‹ã£ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                
        except requests.exceptions.RequestException as e:
            print(f"æ¥½å¤©APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    return all_products

def update_products_csv(new_products):
    """
    æ–°ã—ã„å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æ—¢å­˜ã®products.csvã«çµ±åˆãƒ»æ›´æ–°ã™ã‚‹é–¢æ•°ã€‚
    ã“ã®é–¢æ•°å†…ã§AIåˆ†æã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    """
    cached_products = get_cached_data()
    
    updated_products = {}
    
    # æ—¢å­˜ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’updated_productsã«ã‚³ãƒ”ãƒ¼
    for item_id, product in cached_products.items():
        updated_products[item_id] = product
    
    for product in new_products:
        item_id = product['id']
        
        if item_id in updated_products:
            # æ—¢å­˜ã®å•†å“ã®å ´åˆã€ä¾¡æ ¼å±¥æ­´ã‚’æ›´æ–°
            existing_product = updated_products[item_id]
            
            # ä¾¡æ ¼å±¥æ­´ã‚’æ›´æ–°
            price_history = existing_product.get('price_history', [])
            current_date = date.today().isoformat()
            current_price = int(product['price'].replace(',', ''))
            
            if not price_history or price_history[-1]['date'] != current_date:
                price_history.append({"date": current_date, "price": current_price})
            
            product['price_history'] = price_history
            
            # æ—¢å­˜ã®å•†å“æƒ…å ±ã§ä¸Šæ›¸ã
            updated_products[item_id].update(product)
            
        else:
            # æ–°è¦å•†å“ã®å ´åˆã¯AIã§ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            print(f"æ–°è¦å•†å“: '{product['name']}' ã®AIãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
            ai_summary, tags, sub_category = generate_ai_metadata(product['name'], product['description'])
            product['ai_summary'] = ai_summary
            product['tags'] = tags
            product['category']['sub'] = sub_category
            
            price_history = [{"date": date.today().isoformat(), "price": int(product['price'].replace(',', ''))}]
            product['price_history'] = price_history
            
            updated_products[item_id] = product
    
    # ä¾¡æ ¼å¤‰å‹•ã«åˆã‚ã›ãŸAIåˆ†æã‚’å¸¸ã«æ›´æ–°
    for item_id, product in updated_products.items():
        try:
            price_history = product.get('price_history', [])
            price_int = int(product['price'].replace(',', ''))
            ai_headline, ai_analysis_text = generate_ai_analysis(product['name'], price_int, price_history)
            product['ai_headline'] = ai_headline
            product['ai_analysis'] = ai_analysis_text
        except ValueError:
            print(f"ä¾¡æ ¼ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {product['price']}")
            product['ai_headline'] = "AIåˆ†ææº–å‚™ä¸­"
            product['ai_analysis'] = "è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚"
    
    final_products = list(updated_products.values())
    save_to_cache(final_products)
    
    print(f"{CACHE_FILE}ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸã€‚ç¾åœ¨ {len(final_products)} å€‹ã®å•†å“ã‚’è¿½è·¡ä¸­ã§ã™ã€‚")
    return final_products

def generate_site(products):
    """products.jsonã‚’èª­ã¿è¾¼ã¿ã€HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
    today = date.today().isoformat()
    for product in products:
        if 'date' not in product:
            product['date'] = today
    products.sort(key=lambda p: p['date'], reverse=True)
    
    categories = {}
    for product in products:
        main_cat = product['category']['main']
        sub_cat = product['category']['sub']
        if main_cat not in categories:
            categories[main_cat] = []
        if sub_cat and sub_cat not in categories[main_cat]:
            categories[main_cat].append(sub_cat)

    sorted_main_cats = sorted(categories.keys())

    def generate_header_footer(current_path, sub_cat_links=None, page_title="ãŠå¾—ãªè²·ã„æ™‚ã‚’è¦‹ã¤ã‘ã‚ˆã†ï¼"):
        if "pages" in current_path:
            base_path = ".."
        elif "category" in current_path:
            base_path = "../.."
        elif "tags" in current_path:
            base_path = ".."
        else:
            base_path = "."
        
        main_links_html = f'<a href="{base_path}/tags/index.html">ã‚¿ã‚°ã‹ã‚‰æ¢ã™</a><span class="separator">|</span>'
        for mc_link in sorted_main_cats:
            main_links_html += f'<a href="{base_path}/category/{mc_link}/index.html">{mc_link}</a><span class="separator">|</span>'
            
        header_html = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“ | {page_title}</title>
    <link rel="stylesheet" href="{base_path}/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <meta name="google-site-verification" content="OmUuOjcxi7HXBKe47sd0WPbzCfbCOFbPj_iueHBk2qo" />
</head>
<body>
    <header>
        <div class="container">
            <h1><a href="{base_path}/index.html">ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“</a></h1>
            <p>ãŠå¾—ãªè²·ã„æ™‚ã‚’è¦‹ã¤ã‘ã‚ˆã†ï¼</p>
        </div>
    </header>
    <div class="search-bar">
        <div class="search-container">
            <input type="text" placeholder="å•†å“åã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢...">
            <button class="search-button">ğŸ”</button>
        </div>
    </div>
    <div class="genre-links-container">
        <div class="genre-links">
            {main_links_html}
        </div>
    </div>
"""
        sub_cat_links_html = ""
        if sub_cat_links:
            sub_cat_links_html += '<div class="genre-links sub-genre-links">'
            for sub_cat_link in sorted(sub_cat_links):
                sub_cat_links_html += f'<a href="{sub_cat_link.replace(" ", "")}.html">{sub_cat_link}</a><span class="separator">|</span>'
            sub_cat_links_html += '</div>'
            header_html += f"""
    <div class="sub-genre-links-container">
        {sub_cat_links_html}
    </div>
"""
        footer_html = f"""
    </main>
    <footer>
        <p>&copy; 2025 ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“. All Rights Reserved.</p>
        <div class="footer-links">
            <a href="{base_path}/privacy.html">ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼</a>
            <a href="{base_path}/disclaimer.html">å…è²¬äº‹é …</a>
            <a href="{base_path}/contact.html">ãŠå•ã„åˆã‚ã›</a>
        </div>
    </footer>
    <script src="{base_path}/script.js"></script>
</body>
</html>
        """
        return header_html, footer_html

    def generate_static_page(file_name, title, content_html):
        page_path = file_name
        header, footer = generate_header_footer(page_path, page_title=title)
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + content_html + footer)
        print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    for root, dirs, files in os.walk('.'):
        for file in files:
            if file.endswith('.html') and not file in ['privacy.html', 'disclaimer.html', 'contact.html', 'sitemap.xml']:
                os.remove(os.path.join(root, file))
    if os.path.exists('category'):
        shutil.rmtree('category')
    if os.path.exists('pages'):
        shutil.rmtree('pages')
    if os.path.exists('tags'):
        shutil.rmtree('tags')

    for main_cat, sub_cats in categories.items():
        main_cat_products = [p for p in products if p['category']['main'] == main_cat]
        page_path = f"category/{main_cat}/index.html"
        os.makedirs(os.path.dirname(page_path), exist_ok=True)
        header, footer = generate_header_footer(page_path, sub_cat_links=sub_cats, page_title=f"{main_cat}ã®å•†å“ä¸€è¦§")
        main_content_html = f"""
    <main class="container">
        <div class="ai-recommendation-section">
            <h2 class="ai-section-title">{main_cat}ã®å•†å“ä¸€è¦§</h2>
            <div class="product-grid">
            """
        products_html = ""
        for product in main_cat_products:
            link_path = os.path.relpath(product['page_url'], os.path.dirname(page_path))
            products_html += f"""
<a href="{link_path}" class="product-card">
    <img src="{product['image_url']}" alt="{product['name']}">
    <div class="product-info">
        <h3 class="product-name">{product['name'][:20] + '...' if len(product['name']) > 20 else product['name']}</h3>
        <p class="product-price">{int(product['price']):,}å††</p>
        <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
        <div class="price-status-content ai-analysis">{product['ai_headline']}</div>
    </div>
</a>
            """
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + main_content_html + products_html + "</div>" + footer)
        print(f"category/{main_cat}/index.html ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
        for sub_cat in sub_cats:
            sub_cat_products = [p for p in products if p['category']['sub'] == sub_cat]
            sub_cat_file_name = f"{sub_cat.replace(' ', '')}.html"
            page_path = f"category/{main_cat}/{sub_cat_file_name}"
            header, footer = generate_header_footer(page_path, page_title=f"{sub_cat}ã®å•†å“ä¸€è¦§")
            main_content_html = f"""
    <main class="container">
        <div class="ai-recommendation-section">
            <h2 class="ai-section-title">{sub_cat}ã®å•†å“ä¸€è¦§</h2>
            <div class="product-grid">
            """
            products_html = ""
            for product in sub_cat_products:
                link_path = os.path.relpath(product['page_url'], os.path.dirname(page_path))
                products_html += f"""
<a href="{link_path}" class="product-card">
    <img src="{product['image_url']}" alt="{product['name']}">
    <div class="product-info">
        <h3 class="product-name">{product['name'][:20] + '...' if len(product['name']) > 20 else product['name']}</h3>
                        <p class="product-price">{int(product['price']):,}å††</p>
                        <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
                        <div class="price-status-content ai-analysis">{product['ai_headline']}</div>
                    </div>
                </a>
                """
            with open(page_path, 'w', encoding='utf-8') as f:
                f.write(header + main_content_html + products_html + "</div>" + footer)
            print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    total_pages = math.ceil(len(products) / PRODUCTS_PER_PAGE)
    for i in range(total_pages):
        start_index = i * PRODUCTS_PER_PAGE
        end_index = start_index + PRODUCTS_PER_PAGE
        paginated_products = products[start_index:end_index]
        page_num = i + 1
        page_path = 'index.html' if page_num == 1 else f'pages/page{page_num}.html'
        if page_num > 1:
            os.makedirs(os.path.dirname(page_path), exist_ok=True)
        header, footer = generate_header_footer(page_path)
        products_html = ""
        for product in paginated_products:
            link_path = os.path.relpath(product['page_url'], os.path.dirname(page_path))
            products_html += f"""
<a href="{link_path}" class="product-card">
    <img src="{product['image_url']}" alt="{product['name']}">
    <div class="product-info">
        <h3 class="product-name">{product['name'][:20] + '...' if len(product['name']) > 20 else product['name']}</h3>
        <p class="product-price">{int(product['price']):,}å††</p>
        <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
        <div class="price-status-content ai-analysis">{product['ai_headline']}</div>
    </div>
</a>
            """
        pagination_html = ""
        if total_pages > 1:
            pagination_html += '<div class="pagination">'
            if page_num > 1:
                prev_link = 'index.html' if page_num == 2 else f'pages/page{page_num - 1}.html'
                pagination_html += f'<a href="{os.path.relpath(prev_link, os.path.dirname(page_path))}" class="prev">å‰ã¸</a>'
            for p in range(1, total_pages + 1):
                page_link = 'index.html' if p == 1 else f'pages/page{p}.html'
                active_class = 'active' if p == page_num else ''
                pagination_html += f'<a href="{os.path.relpath(page_link, os.path.dirname(page_path))}" class="{active_class}">{p}</a>'
            if page_num < total_pages:
                next_link = f'pages/page{page_num + 1}.html'
                pagination_html += f'<a href="{os.path.relpath(next_link, os.path.dirname(page_path))}" class="next">æ¬¡ã¸</a>'
            pagination_html += '</div>'
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + '<main class="container"><div class="ai-recommendation-section"><h2 class="ai-section-title">ä»ŠãŒè²·ã„æ™‚ï¼ãŠå¾—ãªæ³¨ç›®ã‚¢ã‚¤ãƒ†ãƒ </h2><div class="product-grid">' + products_html + '</div>' + pagination_html + '</main>' + footer)
        print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    for product in products:
        page_path = product['page_url']
        dir_name = os.path.dirname(page_path)
        if dir_name:
            os.makedirs(dir_name, exist_ok=True)
        header, footer = generate_header_footer(page_path, page_title=f"{product['name']}ã®è²·ã„æ™‚æƒ…å ±")
        ai_analysis_block_html = f"""
            <div class="ai-analysis-block">
                <div class="ai-analysis-text">
                    <h2>AIã«ã‚ˆã‚‹è²·ã„æ™‚åˆ†æ</h2>
                    <p>{product['ai_analysis']}</p>
                </div>
            </div>
        """
        specs_html = ""
        if "specs" in product:
            specs_html = f"""
                <div class="item-specs">
                    <h2>è£½å“ä»•æ§˜ãƒ»ã‚¹ãƒšãƒƒã‚¯</h2>
                    <p>{product.get('specs', '')}</p>
                </div>
            """
        # ä¾¡æ ¼å±¥æ­´ã‚°ãƒ©ãƒ•ã®JavaScript
        price_history_json = json.dumps(product.get('price_history', []))
        price_chart_html = f"""
        <div class="price-chart-section">
            <h2>ä¾¡æ ¼æ¨ç§»ã‚°ãƒ©ãƒ•</h2>
            <canvas id="priceChart" data-history='{price_history_json}'></canvas>
        </div>
        """
        purchase_button_html = f"""
        <div class="purchase-buttons">
            <a href="{product['rakuten_url']}" class="purchase-button rakuten" target="_blank">æ¥½å¤©å¸‚å ´ã§è³¼å…¥ã™ã‚‹</a>
        </div>
        """
        
        affiliate_links_html = f"""
            <div class="lowest-price-section">
                <p class="lowest-price-label">æœ€å®‰å€¤ã‚·ãƒ§ãƒƒãƒ—ã‚’ãƒã‚§ãƒƒã‚¯ï¼</p>
                <div class="lowest-price-buttons">
                    <a href="{product.get("amazon_url", "https://www.amazon.co.jp/")}" class="btn shop-link amazon" target="_blank">Amazonã§è¦‹ã‚‹</a>
                    <a href="{product.get("rakuten_url", "https://www.rakuten.co.jp/")}" class="btn shop-link rakuten" target="_blank">æ¥½å¤©å¸‚å ´ã§è¦‹ã‚‹</a>
                    <a href="{product.get("yahoo_url", "https://shopping.yahoo.co.jp/")}" class="btn shop-link yahoo" target="_blank">Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã§è¦‹ã‚‹</a>
                </div>
            </div>
        """
        item_html_content = f"""
<main class="container">
    <div class="product-detail">
        <div class="item-detail">
            <div class="item-image">
                <img src="{product['image_url']}" alt="{product['name']}" class="main-product-image">
            </div>
            <div class="item-info">
                <h1 class="item-name">{product['name']}</h1>
                <p class="item-category">ã‚«ãƒ†ã‚´ãƒªï¼š<a href="{os.path.relpath('category/' + product['category']['main'] + '/index.html', os.path.dirname(page_path))}">{product['category']['main']}</a> &gt;
                <a href="{os.path.relpath('category/' + product['category']['main'] + '/' + product['category']['sub'].replace(' ', '') + '.html', os.path.dirname(page_path))}">{product['category']['sub']}</a></p>
                <div class="price-section">
                    <p class="current-price">ç¾åœ¨ã®ä¾¡æ ¼ï¼š<span>{int(product['price']):,}</span>å††</p>
                </div>
                <div class="ai-recommendation-section">
                    <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
                    <div class="price-status-content ai-analysis">{product['ai_headline']}</div>
                </div>
                {purchase_button_html}
                {ai_analysis_block_html}
                {price_chart_html}
                {affiliate_links_html}
                <div class="item-description">
                    <h2>AIã«ã‚ˆã‚‹å•†å“ãƒã‚¤ãƒ©ã‚¤ãƒˆ</h2>
                    <p>{product.get('ai_summary', '')}</p>
                </div>
                {specs_html}
                <div class="product-tags">
                    {"".join([f'<a href="../tags/{tag}.html" class="tag-button">#{tag}</a>' for tag in product.get('tags', [])])}
                </div>
            </div>
        </div>
    </div>
</main>
"""
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + item_html_content + footer)
        print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    # ã‚¿ã‚°ä¸€è¦§ãƒšãƒ¼ã‚¸ã¨å€‹åˆ¥ã‚¿ã‚°ãƒšãƒ¼ã‚¸ã®ç”Ÿæˆ
    all_tags = sorted(list(set(tag for product in products for tag in product.get('tags', []))))
    
    if all_tags:
        os.makedirs('tags', exist_ok=True)
        
        # ã‚¿ã‚°ä¸€è¦§ãƒšãƒ¼ã‚¸
        tag_list_html_content = f"""
<main class="container">
    <div class="ai-recommendation-section">
        <h2 class="ai-section-title">ã‚¿ã‚°ã‹ã‚‰æ¢ã™</h2>
        <div class="product-tags all-tags-list">
            {"".join([f'<a href="{tag}.html" class="tag-button">#{tag}</a>' for tag in all_tags])}
        </div>
    </div>
</main>
"""
        tag_header, tag_footer = generate_header_footer('tags/index.html', page_title="ã‚¿ã‚°ä¸€è¦§")
        with open('tags/index.html', 'w', encoding='utf-8') as f:
            f.write(tag_header + tag_list_html_content + tag_footer)
        print("ã‚¿ã‚°ä¸€è¦§ãƒšãƒ¼ã‚¸: tags/index.html ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
        
        # å€‹åˆ¥ã‚¿ã‚°ãƒšãƒ¼ã‚¸
        for tag in all_tags:
            tag_page_path = f'tags/{tag}.html'
            tag_products = [product for product in products if tag in product.get('tags', [])]
            tag_page_content = f"""
<main class="container">
    <div class="ai-recommendation-section">
        <h2 class="ai-section-title">#{tag} ã®å•†å“ä¸€è¦§</h2>
        <div class="product-grid">
            {"".join([f'''
            <a href="../{product['page_url']}" class="product-card">
                <img src="{product['image_url']}" alt="{product['name']}">
                <div class="product-info">
                    <h3 class="product-name">{product['name'][:20] + '...' if len(product['name']) > 20 else product['name']}</h3>
                    <p class="product-price">{int(product['price']):,}å††</p>
                    <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
                    <div class="price-status-content ai-analysis">{product['ai_headline']}</div>
                </div>
            </a>
            ''' for product in tag_products])}
        </div>
    </div>
</main>
"""
            tag_header, tag_footer = generate_header_footer(tag_page_path, page_title=f"#{tag} ã®å•†å“ä¸€è¦§")
            with open(tag_page_path, 'w', encoding='utf-8') as f:
                f.write(tag_header + tag_page_content + tag_footer)
            print(f"ã‚¿ã‚°ãƒšãƒ¼ã‚¸: {tag_page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")

    contact_content = """
    <main class="container">
        <div class="static-content">
            <h1>ãŠå•ã„åˆã‚ã›</h1>
            <p>ã”è³ªå•ã‚„ã”è¦æœ›ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€ä»¥ä¸‹ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¾ã§ã”é€£çµ¡ãã ã•ã„ã€‚</p>
            <p>ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹: sokux001@gmail.com</p>
        </div>
    </main>
    """
    generate_static_page("contact.html", "ãŠå•ã„åˆã‚ã›", contact_content)
    privacy_content = """
    <main class="container">
        <div class="static-content">
            <h1>ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼</h1>
            <p>å½“ã‚µã‚¤ãƒˆã¯ã€Googleã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚åé›†ã•ã‚Œã‚‹æƒ…å ±ã‚„ãã®åˆ©ç”¨ç›®çš„ã«ã¤ã„ã¦ã¯ã€Googleã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã‚’ã”ç¢ºèªãã ã•ã„ã€‚</p>
            <p>å½“ã‚µã‚¤ãƒˆã¯ã€Amazon.co.jpã€æ¥½å¤©å¸‚å ´ã€Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚’å®£ä¼ã—ãƒªãƒ³ã‚¯ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã‚µã‚¤ãƒˆãŒç´¹ä»‹æ–™ã‚’ç²å¾—ã§ãã‚‹æ‰‹æ®µã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã«è¨­å®šã•ã‚ŒãŸã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å‚åŠ è€…ã§ã™ã€‚</p>
        </div>
    </main>
    """
    generate_static_page("privacy.html", "ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼", privacy_content)
    disclaimer_content = """
    <main class="container">
        <div class="static-content">
            <h1>å…è²¬äº‹é …</h1>
            <p>æœ¬ã‚µã‚¤ãƒˆã«æ²è¼‰ã•ã‚Œã¦ã„ã‚‹æƒ…å ±ã¯ã€æ­£ç¢ºæ€§ã‚„å®Œå…¨æ€§ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</p>
            <p>ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ã‚’é€šã˜ã¦è³¼å…¥ã•ã‚ŒãŸå•†å“ã«é–¢ã™ã‚‹ãƒˆãƒ©ãƒ–ãƒ«ã«ã¤ã„ã¦ã¯ã€å½“ã‚µã‚¤ãƒˆã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</p>
        </div>
    </main>
    """
    generate_static_page("disclaimer.html", "å…è²¬äº‹é …", disclaimer_content)

    def create_sitemap():
        base_url = "https://w41w41-beep.github.io/kaidoki-navi/"
        sitemap_content = '<?xml version="1.0" encoding="UTF-8"?>\n'
        sitemap_content += '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'
        sitemap_content += '  <url>\n'
        sitemap_content += f'    <loc>{base_url}</loc>\n'
        sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
        sitemap_content += '    <changefreq>daily</changefreq>\n'
        sitemap_content += '    <priority>1.0</priority>\n'
        sitemap_content += '  </url>\n'
        categories = {}
        for product in products:
            main_cat = product['category']['main']
            sub_cat = product['category']['sub']
            if main_cat not in categories:
                categories[main_cat] = set()
            categories[main_cat].add(sub_cat)
        for main_cat, sub_cats in categories.items():
            sitemap_content += '  <url>\n'
            sitemap_content += f'    <loc>{base_url}category/{main_cat}/index.html</loc>\n'
            sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
            sitemap_content += '    <changefreq>daily</changefreq>\n'
            sitemap_content += '    <priority>0.8</priority>\n'
            sitemap_content += '  </url>\n'
            for sub_cat in sub_cats:
                sitemap_content += '  <url>\n'
                sitemap_content += f'    <loc>{base_url}category/{main_cat}/{sub_cat.replace(" ", "")}.html</loc>\n'
                sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
                sitemap_content += '    <changefreq>daily</changefreq>\n'
                sitemap_content += '    <priority>0.7</priority>\n'
                sitemap_content += '  </url>\n'
        for tag in all_tags:
            sitemap_content += '  <url>\n'
            sitemap_content += f'    <loc>{base_url}tags/{tag}.html</loc>\n'
            sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
            sitemap_content += '    <changefreq>daily</changefreq>\n'
            sitemap_content += '    <priority>0.6</priority>\n'
            sitemap_content += '  </url>\n'
        for product in products:
            sitemap_content += '  <url>\n'
            sitemap_content += f'    <loc>{base_url}{product["page_url"]}</loc>\n'
            sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
            sitemap_content += '    <changefreq>daily</changefreq>\n'
            sitemap_content += '    <priority>0.6</priority>\n'
            sitemap_content += '  </url>\n'
        static_pages = ["privacy.html", "disclaimer.html", "contact.html"]
        for page in static_pages:
            sitemap_content += '  <url>\n'
            sitemap_content += f'    <loc>{base_url}{page}</loc>\n'
            sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
            sitemap_content += '    <changefreq>monthly</changefreq>\n'
            sitemap_content += '    <priority>0.5</priority>\n'
            sitemap_content += '  </url>\n'
        sitemap_content += '</urlset>'
        with open('sitemap.xml', 'w', encoding='utf-8') as f:
            f.write(sitemap_content)
        print("sitemap.xml ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    create_sitemap()
    print("ã‚µã‚¤ãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    rakuten_products = fetch_rakuten_items()
    products = update_products_csv(rakuten_products)
    generate_site(products)
