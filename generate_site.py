# -*- coding: utf-8 -*-
import json
import math
import os
import shutil
import time
from datetime import date
import requests
import csv
import urllib.parse
from urllib.parse import urlparse

# ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’å®šç¾©ã™ã‚‹ãƒªã‚¹ãƒˆ
PRODUCT_CATEGORIES = {
    "ãƒ‘ã‚½ã‚³ãƒ³ãƒ»å‘¨è¾ºæ©Ÿå™¨": [
        "ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³", "ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—PC", "ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰", "ãƒã‚¦ã‚¹",
        "ãƒ¢ãƒ‹ã‚¿ãƒ¼", "ãƒ—ãƒªãƒ³ã‚¿ãƒ¼", "ãƒ«ãƒ¼ã‚¿ãƒ¼", "ã‚²ãƒ¼ãƒŸãƒ³ã‚°PC"
    ],
    "å®¶é›»": [
        "ã‚«ãƒ¡ãƒ©", "ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª", "ã‚­ãƒƒãƒãƒ³å®¶é›»",
        "ç…§æ˜", "æƒé™¤æ©Ÿ", "ãƒ†ãƒ¬ãƒ“", "å†·è”µåº«", "æ´—æ¿¯æ©Ÿ" 
    ],
    "ç¾å®¹ãƒ»å¥åº·": [ 
        "ç¾å®¹å®¶é›»", "ãƒ€ã‚¤ã‚¨ãƒƒãƒˆã‚µãƒ—ãƒª", "ãƒ—ãƒ­ãƒ†ã‚¤ãƒ³", "ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹æ©Ÿå™¨",
        "ãƒãƒƒã‚µãƒ¼ã‚¸æ©Ÿ", "ãƒ˜ã‚¢ã‚±ã‚¢", "ã‚¹ã‚­ãƒ³ã‚±ã‚¢", "ç¡çœ ã‚µãƒãƒ¼ãƒˆ"
    ]
}

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£/ç‰¹é›†ã‚«ãƒ†ã‚´ãƒªã¨ãƒ‘ã‚¹ã‚’å®šç¾© (å‹•çš„ãªãŠå¾—æƒ…å ±)
UTILITY_CATEGORIES = {
    "AIã§æ¢ã™": "ai_search.html",
    "ã‚¿ã‚°ã§æ¢ã™": "tags/index.html",
    # ãƒã‚¤ãƒ³ãƒˆç‰¹åŒ–ã¨æœŸé–“é™å®šã‚»ãƒ¼ãƒ«ã¯ã€Œå‹•çš„ãªãŠå¾—æƒ…å ±ã€ã¨ã—ã¦UTILITYã«é…ç½®
    "ãƒã‚¤ãƒ³ãƒˆç‰¹åŒ–": "category/ãƒã‚¤ãƒ³ãƒˆç‰¹åŒ–/index.html",
    "æœŸé–“é™å®šã‚»ãƒ¼ãƒ«": "category/æœŸé–“é™å®šã‚»ãƒ¼ãƒ«/index.html"
}

# 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®å•†å“æ•°ã‚’å®šç¾©
PRODUCTS_PER_PAGE = 24

# APIã‚­ãƒ¼ã¯å®Ÿè¡Œç’°å¢ƒãŒè‡ªå‹•çš„ã«ä¾›çµ¦ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ç©ºã®æ–‡å­—åˆ—ã¨ã—ã¾ã™ã€‚
# OpenAI APIã®è¨­å®š
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
MODEL_NAME = "gpt-4o-mini"
CACHE_FILE = 'products.csv'

# Amazonã¨Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã®ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ã‚’å®šç¾©
AMAZON_AFFILIATE_LINK = "https://amzn.to/46zr68v"
YAHOO_AFFILIATE_LINK = "//ck.jp.ap.valuecommerce.com/servlet/referral?sid=3754088&pid=892109155"

# CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã‚’å›ºå®š
CSV_FIELDNAMES = [
    'id', 'name', 'price', 'image_url', 'rakuten_url', 'yahoo_url', 'amazon_url',
    'page_url', 'category', 'ai_headline', 'ai_analysis', 'description',
    'ai_summary', 'tags', 'date', 'main_ec_site', 'price_history', 'source'
]

def get_cached_data():
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå•†å“ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    cached_data = {}
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                if 'id' not in reader.fieldnames:
                    print("è­¦å‘Š: CSVãƒ•ã‚¡ã‚¤ãƒ«ã«'id'ãƒ˜ãƒƒãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                    return {}

                for row in reader:
                    if not row.get('id'):
                        continue
                    product_id = row['id']
                    
                    # JSONæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æ­£ã—ããƒ‘ãƒ¼ã‚¹
                    for key in ['price_history', 'tags', 'category']:
                        if key in row and isinstance(row[key], str):
                            try:
                                row[key] = json.loads(row[key])
                            except (json.JSONDecodeError, TypeError):
                                print(f"è­¦å‘Š: ID {product_id} ã® {key} ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                                row[key] = [] if key in ['price_history', 'tags'] else {"main": "ä¸æ˜", "sub": ""}
                    
                    # categoryãŒè¾æ›¸å½¢å¼ã§ãªã„å ´åˆã«è£œå®Œ
                    if 'category' in row and not isinstance(row['category'], dict):
                        row['category'] = {"main": "ä¸æ˜", "sub": ""}
                    
                    cached_data[product_id] = row
        except csv.Error as e:
            print(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return {}
    return cached_data

def save_to_cache(products):
    """å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹"""
    if not products:
        if os.path.exists(CACHE_FILE):
            os.remove(CACHE_FILE)
        return

    with open(CACHE_FILE, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=CSV_FIELDNAMES)
        writer.writeheader()
        for product in products:
            product_to_write = product.copy()
            # è¾æ›¸ã‚„ãƒªã‚¹ãƒˆã¯JSONæ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦ä¿å­˜
            product_to_write['price_history'] = json.dumps(product_to_write.get('price_history', []), ensure_ascii=False)
            product_to_write['tags'] = json.dumps(product_to_write.get('tags', []), ensure_ascii=False)
            product_to_write['category'] = json.dumps(product_to_write.get('category', {"main": "ä¸æ˜", "sub": ""}), ensure_ascii=False)
            writer.writerow(product_to_write)

def _call_openai_api(prompt, response_format):
    """OpenAI APIã‚’å‘¼ã³å‡ºã™å…±é€šé–¢æ•°"""
    if not OPENAI_API_KEY:
        print("è­¦å‘Š: OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return None

    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {OPENAI_API_KEY}'
    }

    payload = {
        "model": MODEL_NAME,
        "messages": [{"role": "system", "content": "ã‚ãªãŸã¯ãƒ—ãƒ­ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"}, {"role": "user", "content": prompt}],
        "response_format": {"type": response_format}
    }

    try:
        response = requests.post(OPENAI_API_URL, headers=headers, data=json.dumps(payload), timeout=20)
        response.raise_for_status()
        result = response.json()
        return json.loads(result.get('choices', [{}])[0].get('message', {}).get('content', '{}'))
    except requests.exceptions.Timeout:
        print("OpenAI APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
    except requests.exceptions.RequestException as e:
        print(f"OpenAI APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    except (IndexError, KeyError, json.JSONDecodeError) as e:
        print(f"OpenAI APIã®å¿œç­”å½¢å¼ãŒä¸æ­£ã§ã™: {e}")
    return None

def map_to_defined_category(sub_category, product_name):
    """
    AIãŒç”Ÿæˆã—ãŸã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’ã€å®šç¾©æ¸ˆã¿ãƒªã‚¹ãƒˆã«ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹ã€‚
    ä¸€è‡´ã™ã‚‹ã‚‚ã®ãŒãªã‘ã‚Œã°ã€å•†å“åã‹ã‚‰ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’æ¨æ¸¬ã™ã‚‹ã€‚
    """
    # AIãŒç”Ÿæˆã—ãŸã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ãŒå®šç¾©æ¸ˆã¿ãƒªã‚¹ãƒˆã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    for main_cat, sub_cats in PRODUCT_CATEGORIES.items():
        if sub_category in sub_cats:
            return main_cat, sub_category
        # éƒ¨åˆ†ä¸€è‡´ã§ã‚‚å¯¾å¿œã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
        if any(sc in product_name.lower() for sc in sub_cats):
            return main_cat, sub_category

    # å®šç¾©æ¸ˆã¿ãƒªã‚¹ãƒˆã«ä¸€è‡´ã™ã‚‹ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ãŒãªã„å ´åˆã€å•†å“åã‹ã‚‰ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’æ¨æ¸¬
    for main_cat, sub_cats in PRODUCT_CATEGORIES.items():
        if any(term in product_name.lower() for term in [main_cat, sub_category]):
            return main_cat, "ãã®ä»–" # ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¯ã€Œãã®ä»–ã€ã«åˆ†é¡
            
    # ã„ãšã‚Œã«ã‚‚å½“ã¦ã¯ã¾ã‚‰ãªã„å ´åˆã€å¯¾è±¡å¤–ã¨ã™ã‚‹
    return 'ãã®ä»–', 'ãã®ä»–'

def generate_ai_metadata(product_name, product_description):
    """å•†å“ã®è¦ç´„ã€ã‚¿ã‚°ã€ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’ç”Ÿæˆã™ã‚‹"""
    prompt = f"""
    ä»¥ä¸‹ã®å•†å“æƒ…å ±ã‚’ã‚‚ã¨ã«ã€ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ã—ã¦æœ€é©ãªã€ç°¡æ½”ã§é­…åŠ›çš„ãªè¦ç´„ã€é–¢é€£ã™ã‚‹ã‚¿ã‚°ï¼ˆ3ã€œ5å€‹ï¼‰ã€ãã—ã¦é©åˆ‡ãªã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆ1ã¤ï¼‰ã‚’æ—¥æœ¬èªã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
    å›ç­”ã¯å¿…ãšJSONå½¢å¼ã§æä¾›ã—ã¦ãã ã•ã„ã€‚JSONã¯ã€Œsummaryã€ã€ã€Œtagsã€ã€ã€Œsub_categoryã€ã®3ã¤ã®ã‚­ãƒ¼ã‚’æŒã¡ã¾ã™ã€‚

    å•†å“å: {product_name}
    å•†å“èª¬æ˜: {product_description}

    è¦ç´„ã®æ–‡ç« ã«ã¯ã€SEOã‚’æ„è­˜ã—ãŸã€Œæ ¼å®‰ã€ã€Œæœ€å®‰å€¤ã€ã€Œã‚»ãƒ¼ãƒ«ã€ã€Œå‰²å¼•ã€ãªã©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªç„¶ã«å«ã‚ã¦ãã ã•ã„ã€‚
    ã‚¿ã‚°ã¯å•†å“ã®ç‰¹å¾´ã‚„ç”¨é€”ã‚’è¡¨ã™å˜èªã‚’ãƒªã‚¹ãƒˆå½¢å¼ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚**ã‚»ãƒ¼ãƒ«ä¸­ã‚„ãƒã‚¤ãƒ³ãƒˆé‚„å…ƒç‡ãŒé«˜ã„å ´åˆã¯ã€Œã‚»ãƒ¼ãƒ«ã€ã‚„ã€Œãƒã‚¤ãƒ³ãƒˆé«˜é‚„å…ƒã€ã¨ã„ã£ãŸã‚¿ã‚°ã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚**
    ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¯ã€å•†å“ã®ã‚¸ãƒ£ãƒ³ãƒ«ã‚’ç´°åˆ†åŒ–ã—ãŸå˜ä¸€ã®å˜èªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
    """
    metadata = _call_openai_api(prompt, "json_object")
    if metadata:
        ai_sub_category = metadata.get('sub_category', "")
        main_cat, sub_cat = map_to_defined_category(ai_sub_category, product_name)
        return metadata.get('summary', "ã“ã®å•†å“ã®è©³ã—ã„èª¬æ˜ã¯æº–å‚™ä¸­ã§ã™ã€‚"), metadata.get('tags', []), main_cat, sub_cat
    
    # AIãŒå¤±æ•—ã—ãŸå ´åˆã‚‚ã€å•†å“åã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’æ¨æ¸¬
    main_cat, sub_cat = map_to_defined_category("", product_name)
    return "ã“ã®å•†å“ã®è©³ã—ã„èª¬æ˜ã¯æº–å‚™ä¸­ã§ã™ã€‚", [], main_cat, sub_cat

def generate_ai_analysis(product_name, product_price, price_history):
    """å•†å“ã®ä¾¡æ ¼åˆ†æãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
    history_text = f"éå»ã®ä¾¡æ ¼å±¥æ­´ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™: {price_history}" if price_history else "ä¾¡æ ¼å±¥æ­´ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
    prompt = f"""
    ã‚ãªãŸã¯ã€ä¾¡æ ¼æ¯”è¼ƒã®å°‚é–€å®¶ã¨ã—ã¦ã€æ¶ˆè²»è€…ã«å•†å“ã®è²·ã„æ™‚ã‚’ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã—ã¾ã™ã€‚å›ç­”ã¯å¿…ãšJSONå½¢å¼ã§æä¾›ã—ã¦ãã ã•ã„ã€‚JSONã¯ã€Œheadlineã€ã¨ã€Œanalysisã€ã®2ã¤ã®ã‚­ãƒ¼ã‚’æŒã¡ã¾ã™ã€‚ã€Œheadlineã€ã¯å•†å“ã®è²·ã„æ™‚ã‚’ä¼ãˆã‚‹ç°¡æ½”ãªä¸€è¨€ã§ã€å¯èƒ½ã§ã‚ã‚Œã°å…·ä½“çš„ãªå‰²å¼•ç‡ã‚„æ•°å­—ã‚’ä½¿ã£ã¦è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚ã€Œanalysisã€ã¯ãªãœè²·ã„æ™‚ãªã®ã‹ã‚’èª¬æ˜ã™ã‚‹è©³ç´°ãªæ–‡ç« ã§ã™ã€‚æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
    {product_name}ã¨ã„ã†å•†å“ã®ç¾åœ¨ã®ä¾¡æ ¼ã¯{product_price}å††ã§ã™ã€‚{history_text}ã€‚ã“ã®å•†å“ã®ä¾¡æ ¼ã«ã¤ã„ã¦ã€å¸‚å ´ã®å‹•å‘ã‚’è¸ã¾ãˆãŸåˆ†æã¨è²·ã„æ™‚ã«é–¢ã™ã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚ç‰¹ã«ä¾¡æ ¼ãŒå‰å›ã¨æ¯”ã¹ã¦ä¸‹ãŒã£ã¦ã„ã‚‹å ´åˆã¯ã€**ã€Œæœ€å®‰å€¤ã€**ã‚„**ã€Œã‚»ãƒ¼ãƒ«ã€**ã¨ã„ã£ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ã£ã¦è²·ã„æ™‚ã‚’å¼·èª¿ã—ã¦ãã ã•ã„ã€‚
    **ãƒã‚¤ãƒ³ãƒˆé‚„å…ƒç‡ãŒé«˜ã„å ´åˆã€ãã®æƒ…å ±ã‚’ã€Œheadlineã€ã«å«ã‚ã¦å¼·èª¿ã—ã¦ãã ã•ã„ã€‚**
    """
    analysis_data = _call_openai_api(prompt, "json_object")
    if analysis_data:
        return analysis_data.get('headline', 'AIåˆ†ææº–å‚™ä¸­'), analysis_data.get('analysis', 'è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚')
    return "AIåˆ†ææº–å‚™ä¸­", "è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚"

def fetch_rakuten_items():
    """æ¥½å¤©APIã‹ã‚‰è¤‡æ•°ã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹é–¢æ•°"""
    app_id = os.environ.get('RAKUTEN_API_KEY')
    if not app_id:
        print("RAKUTEN_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return []

    # äº‹å‰å®šç¾©ã—ãŸã‚«ãƒ†ã‚´ãƒªãƒ¼ã«åˆã‚ã›ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’èª¿æ•´
    keywords = ['ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³', 'å†·è”µåº«', 'ãƒ€ã‚¤ã‚¨ãƒƒãƒˆã‚µãƒ—ãƒª', 'ãƒãƒƒã‚µãƒ¼ã‚¸æ©Ÿ'] # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ›´æ–°
    all_products = []

    for keyword in keywords:
        url = f"https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706?applicationId={app_id}&keyword={keyword}&format=json&sort=-reviewCount&hits=1"
        try:
            print(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ '{keyword}' ã§å•†å“ã‚’æ¤œç´¢ä¸­...")
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            data = response.json()
            items = data.get('Items', [])

            if items:
                print(f"'{keyword}' ã§ {len(items)} ä»¶ã®å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
                for item in items:
                    item_data = item['Item']
                    description = item_data.get('itemCaption', '')

                    new_product = {
                        "id": item_data['itemCode'],
                        "name": item_data['itemName'],
                        "price": str(item_data['itemPrice']),
                        "image_url": item_data.get('mediumImageUrls', [{}])[0].get('imageUrl', ''),
                        "rakuten_url": item_data.get('itemUrl', ''),
                        # ä¿®æ­£å¾Œã®Yahoo!ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ã‚’å‰²ã‚Šå½“ã¦
                        "yahoo_url": YAHOO_AFFILIATE_LINK,
                        "amazon_url": AMAZON_AFFILIATE_LINK,
                        "page_url": f"pages/{item_data['itemCode'].replace(':', '_')}.html",
                        "category": {"main": "", "sub": ""},
                        "ai_headline": "",
                        "ai_analysis": "",
                        "description": description,
                        "ai_summary": "",
                        "tags": [],
                        "date": date.today().isoformat(),
                        "main_ec_site": "æ¥½å¤©",
                        "price_history": [],
                        'source': 'rakuten',
                    }
                    all_products.append(new_product)
        except requests.exceptions.RequestException as e:
            print(f"æ¥½å¤©APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        except (IndexError, KeyError) as e:
            print(f"æ¥½å¤©APIã®å¿œç­”å½¢å¼ãŒä¸æ­£ã§ã™: {e}")

    print(f"åˆè¨ˆ {len(all_products)} ä»¶ã®å•†å“ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
    return all_products

def update_products_csv(new_products):
    """æ–°ã—ã„å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æ—¢å­˜ã®products.csvã«çµ±åˆãƒ»æ›´æ–°ã™ã‚‹é–¢æ•°"""
    cached_products = get_cached_data()
    updated_products = {}

    for item_id, product in cached_products.items():
        if 'source' not in product:
            product['source'] = 'rakuten'
        updated_products[item_id] = product

    final_products_to_save = []
    for product in new_products:
        item_id = product['id']
        is_new = item_id not in updated_products
        is_price_changed = False
        current_date = date.today().isoformat()
        try:
            current_price = int(str(product['price']).replace(',', ''))
        except (ValueError, KeyError):
            print(f"ä¾¡æ ¼ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {product.get('price', 'ä¸æ˜')}")
            continue

        product['source'] = 'rakuten'

        if is_new:
            # æ–°è¦å•†å“ã®å‡¦ç†
            product['price_history'] = [{"date": current_date, "price": current_price}]
            print(f"æ–°è¦å•†å“ '{product['name']}' ã‚’è¿½åŠ ã—ã¾ã™ã€‚AIãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
            ai_summary, tags, main_cat, sub_cat = generate_ai_metadata(product['name'], product['description'])
            
            # å®šç¾©æ¸ˆã¿ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«ãªã„å ´åˆã¯ã€Œãã®ä»–ã€ã¨ã—ã¦è¿½åŠ 
            if main_cat == 'ãã®ä»–':
                print(f"å•†å“ '{product['name']}' ã¯å®šç¾©æ¸ˆã¿ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«å±ã•ãªã„ãŸã‚ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’ã€Œãã®ä»–ã€ã«è¨­å®šã—ã¾ã™ã€‚")
            
            product['ai_summary'] = ai_summary
            product['tags'] = tags
            product['category']['main'] = main_cat
            product['category']['sub'] = sub_cat
            
            ai_headline, ai_analysis_text = generate_ai_analysis(product['name'], current_price, product['price_history'])
            product['ai_headline'] = ai_headline
            product['ai_analysis'] = ai_analysis_text
            final_products_to_save.append(product)

        else:
            # æ—¢å­˜å•†å“ã®å‡¦ç†
            existing_product = updated_products[item_id]
            price_history = existing_product.get('price_history', [])
            
            if not price_history or price_history[-1].get('date') != current_date:
                price_history.append({"date": current_date, "price": current_price})
            
            last_price = price_history[-2]['price'] if len(price_history) >= 2 else None
            if last_price and last_price != current_price:
                is_price_changed = True
            
            existing_product['price_history'] = price_history
            existing_product['price'] = str(current_price)

            if not existing_product.get('ai_summary') or not existing_product.get('tags') or not existing_product['category'].get('sub'):
                print(f"å•†å“ '{existing_product['name']}' ã®AIãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è£œå®Œä¸­...")
                ai_summary, tags, main_cat, sub_cat = generate_ai_metadata(existing_product['name'], existing_product['description'])
                
                if main_cat == 'ãã®ä»–':
                    print(f"å•†å“ '{existing_product['name']}' ã¯å®šç¾©æ¸ˆã¿ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«å±ã•ãªã„ãŸã‚ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’ã€Œãã®ä»–ã€ã«è¨­å®šã—ã¾ã™ã€‚")
                
                existing_product['ai_summary'] = ai_summary if not existing_product.get('ai_summary') else existing_product['ai_summary']
                existing_product['tags'] = tags if not existing_product.get('tags') else existing_product['tags']
                existing_product['category']['main'] = main_cat if not existing_product['category'].get('main') else existing_product['category']['main']
                existing_product['category']['sub'] = sub_cat if not existing_product['category'].get('sub') else existing_product['category']['sub']

            if is_price_changed or not existing_product.get('ai_headline') or not existing_product.get('ai_analysis'):
                print(f"å•†å“ '{existing_product['name']}' ã®AIåˆ†æã‚’æ›´æ–°/ç”Ÿæˆä¸­...")
                ai_headline, ai_analysis_text = generate_ai_analysis(existing_product['name'], current_price, price_history)
                existing_product['ai_headline'] = ai_headline
                existing_product['ai_analysis'] = ai_analysis_text
            else:
                print(f"å•†å“ '{existing_product['name']}' ã®ä¾¡æ ¼ã«å¤‰å‹•ãŒãªã„ãŸã‚ã€AIåˆ†æã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚")
            
            final_products_to_save.append(existing_product)
    
    save_to_cache(final_products_to_save)
    print(f"{CACHE_FILE}ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸã€‚ç¾åœ¨ {len(final_products_to_save)} å€‹ã®å•†å“ã‚’è¿½è·¡ä¸­ã§ã™ã€‚")
    return final_products_to_save

def generate_header_footer(current_path, page_title="ãŠå¾—ãªè²·ã„æ™‚ã‚’è¦‹ã¤ã‘ã‚ˆã†ï¼"):
    """ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ãƒ•ãƒƒã‚¿ãƒ¼ã®HTMLã‚’ç”Ÿæˆã™ã‚‹"""
    # ç¾åœ¨ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®ç›¸å¯¾ãƒ‘ã‚¹ã‚’è¨ˆç®—
    rel_path_to_root = os.path.relpath('.', os.path.dirname(current_path))
    if rel_path_to_root == '.':
        base_path = './'
    else:
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåãŒç©ºã§ãªã„å ´åˆã€æœ«å°¾ã«ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’è¿½åŠ 
        if rel_path_to_root:
            base_path = rel_path_to_root + '/'
        else:
            base_path = './'

    def generate_links_html(links):
        return "".join([f'<a href="{url}">{text}</a><span class="separator">|</span>' for text, url in links])
        
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒªãƒ³ã‚¯ã®ç”Ÿæˆ
    utility_links = []
    for text, path in UTILITY_CATEGORIES.items():
        utility_links.append((text, f"{base_path}{path}"))

    # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ç”Ÿæˆ (ãƒ•ãƒ©ãƒƒãƒˆãƒªã‚¹ãƒˆ)
    main_category_links = []
    all_categories = list(PRODUCT_CATEGORIES.keys()) + ['ãã®ä»–']
    for cat in all_categories:
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã¸ã®ãƒªãƒ³ã‚¯ã®ã¿ã‚’ç”Ÿæˆ
        link_path = f"{base_path}category/{cat}/index.html"
        main_category_links.append((cat, link_path))


    header_html = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“ | {page_title}</title>
    <link rel="stylesheet" href="{base_path}style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <meta name="google-site-verification" content="OmUuOjcxi7HXBKe47sd0WPbzCfbCOFbPj_iueHBk2qo" />
</head>
<body>
    <header>
        <div class="container">
            <h1><a href="{base_path}">ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“</a></h1>
            <p>ãŠå¾—ãªè²·ã„æ™‚ã‚’è¦‹ã¤ã‘ã‚ˆã†ï¼</p>
        </div>
    </header>
    <div class="search-bar">
        <div class="search-container">
            <input type="text" placeholder="å•†å“åã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢...">
            <button class="search-button">ğŸ”</button>
        </div>
    </div>
    <!-- 1. ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒªãƒ³ã‚¯ (AIã€ã‚¿ã‚°ã€ã‚»ãƒ¼ãƒ«ãªã©) -->
    <div class="genre-links-container utility-nav">
        <div class="genre-links">
            {generate_links_html(utility_links)}
        </div>
    </div>
    <!-- 2. ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼ (ãƒ•ãƒ©ãƒƒãƒˆãƒªã‚¹ãƒˆ) -->
    <div class="genre-links-container main-category-nav-flat">
        <div class="genre-links">
            {generate_links_html(main_category_links)}
        </div>
    </div>
    <!-- ä»¥å‰ã®å‹•çš„ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ã‚³ãƒ³ãƒ†ãƒŠã¯å‰Šé™¤ -->
    <script src="{base_path}script.js"></script>
"""
    
    footer_html = f"""
    </main>
    <footer>
        <p>&copy; 2025 ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“. All Rights Reserved.</p>
        <div class="footer-links">
            <a href="{base_path}privacy.html">ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼</a>
            <a href="{base_path}disclaimer.html">å…è²¬äº‹é …</a>
            <a href="{base_path}contact.html">ãŠå•ã„åˆã‚ã›</a>
        </div>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {{
            const priceChartCanvas = document.getElementById('priceChart');
            if (priceChartCanvas) {{
                try {{
                    const dataHistory = JSON.parse(priceChartCanvas.getAttribute('data-history'));
                    if (dataHistory && Array.isArray(dataHistory) && dataHistory.length > 0) {{
                        const dates = dataHistory.map(item => item.date);
                        const prices = dataHistory.map(item => item.price);
                        new Chart(priceChartCanvas, {{
                            type: 'line',
                            data: {{
                                labels: dates,
                                datasets: [{{
                                    label: 'ä¾¡æ ¼æ¨ç§»',
                                    data: prices,
                                    borderColor: 'rgb(75, 192, 192)',
                                    tension: 0.1
                                }}]
                            }},
                            options: {{
                                responsive: true,
                                scales: {{
                                    x: {{
                                        title: {{
                                            display: true,
                                            text: 'æ—¥ä»˜'
                                        }}
                                    }},
                                    y: {{
                                        title: {{
                                            display: true,
                                            text: 'ä¾¡æ ¼ï¼ˆå††ï¼‰'
                                        }}
                                    }}
                                }}
                            }}
                        }});
                    }}
                }} catch (e) {{
                    console.error('ä¾¡æ ¼ã‚°ãƒ©ãƒ•ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸ:', e);
                }}
            }}
        }});
    </script>
</body>
</html>"""
    return header_html, footer_html

def generate_product_card_html(product, page_path):
    """å•†å“ã‚«ãƒ¼ãƒ‰ã®HTMLã‚’ç”Ÿæˆã™ã‚‹"""
    # å•†å“ã‚«ãƒ¼ãƒ‰ã®ãƒªãƒ³ã‚¯ã¯ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹
    link_path = os.path.relpath(product['page_url'], os.path.dirname(page_path))
    return f"""
<a href="{link_path}" class="product-card">
    <img src="{product.get('image_url', '')}" alt="{product.get('name', 'å•†å“ç”»åƒ')}">
    <div class="product-info">
        <h3 class="product-name">{product.get('name', 'å•†å“å')[:20] + '...' if len(product.get('name', '')) > 20 else product.get('name', 'å•†å“å')}</h3>
        <p class="product-price">{int(product.get('price', 0)):,}å††</p>
        <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
        <div class="price-status-content ai-analysis">{product.get('ai_headline', 'AIåˆ†ææº–å‚™ä¸­')}</div>
    </div>
</a>"""


def generate_site(products):
    """products.jsonã‚’èª­ã¿è¾¼ã¿ã€HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
    today = date.today().isoformat()
    for product in products:
        if 'date' not in product:
            product['date'] = today
    products.sort(key=lambda p: p.get('date', '1970-01-01'), reverse=True)

    # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’äº‹å‰ã«å®šç¾©ã—ãŸãƒªã‚¹ãƒˆã‹ã‚‰å–å¾—
    categories = PRODUCT_CATEGORIES
    
    # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã”ã¨ã®å•†å“ãƒªã‚¹ãƒˆã‚’æº–å‚™
    category_products = {cat: [] for cat in categories.keys()}
    category_products['ãã®ä»–'] = []
    
    all_tags = set()
    for product in products:
        main_cat = product.get('category', {}).get('main', 'ãã®ä»–')
        if main_cat in category_products:
            category_products[main_cat].append(product)
        else:
            category_products['ãã®ä»–'].append(product)
        all_tags.update(product.get('tags', []))

    # æ—¢å­˜ã®ç”Ÿæˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    for dir_name in ['pages', 'category', 'tags']:
        if os.path.exists(dir_name):
            shutil.rmtree(dir_name, ignore_errors=True)
        os.makedirs(dir_name, exist_ok=True)
    
    # ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã®ç”Ÿæˆ
    total_pages = math.ceil(len(products) / PRODUCTS_PER_PAGE)
    for i in range(total_pages):
        start_index = i * PRODUCTS_PER_PAGE
        end_index = start_index + PRODUCTS_PER_PAGE
        paginated_products = products[start_index:end_index]
        page_num = i + 1
        page_path = 'index.html' if page_num == 1 else f'pages/page{page_num}.html'
        
        products_html = "".join([generate_product_card_html(p, page_path) for p in paginated_products])
        
        pagination_html = ""
        if total_pages > 1:
            pagination_html += '<div class="pagination">'
            if page_num > 1:
                prev_link = 'index.html' if page_num == 2 else f'pages/page{page_num - 1}.html'
                pagination_html += f'<a href="{os.path.relpath(prev_link, os.path.dirname(page_path))}" class="prev">å‰ã¸</a>'
            for p in range(1, total_pages + 1):
                page_link = 'index.html' if p == 1 else f'pages/page{p}.html'
                active_class = 'active' if p == page_num else ''
                pagination_html += f'<a href="{os.path.relpath(page_link, os.path.dirname(page_path))}" class="{active_class}">{p}</a>'
            if page_num < total_pages:
                next_link = f'pages/page{page_num + 1}.html'
                pagination_html += f'<a href="{os.path.relpath(next_link, os.path.dirname(page_path))}" class="next">æ¬¡ã¸</a>'
            pagination_html += '</div>'

        main_content_html = f"""
<main class="container">
    <div class="ai-recommendation-section">
        <h2 class="ai-section-title">ä»ŠãŒè²·ã„æ™‚ï¼ãŠå¾—ãªæ³¨ç›®ã‚¢ã‚¤ãƒ†ãƒ </h2>
        <div class="product-grid">
            {products_html}
        </div>
        {pagination_html}
    </div>
</main>
"""
        header, footer = generate_header_footer(page_path)
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + main_content_html + footer)
        print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã”ã¨ã®ãƒšãƒ¼ã‚¸ç”Ÿæˆï¼ˆãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ã¿ï¼‰
    all_categories = list(categories.keys()) + ['ãã®ä»–']
    for main_cat in all_categories:
        main_cat_products = category_products.get(main_cat, [])
        if not main_cat_products:
            print(f"è­¦å‘Š: ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼ '{main_cat}' ã«è©²å½“ã™ã‚‹å•†å“ãŒãªã„ãŸã‚ã€ãƒšãƒ¼ã‚¸ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
            continue
            
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã®ã¿ã‚’ç”Ÿæˆ
        page_path = f"category/{main_cat}/index.html"
        os.makedirs(os.path.dirname(page_path), exist_ok=True)
        products_html = "".join([generate_product_card_html(p, page_path) for p in main_cat_products])
        main_content_html = f"""
<main class="container">
    <div class="ai-recommendation-section">
        <h2 class="ai-section-title">{main_cat}ã®å•†å“ä¸€è¦§</h2>
        <!-- ã‚¿ã‚°ãŒã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®å½¹å‰²ã‚’æœãŸã™ã“ã¨ã‚’ç¤ºã™ -->
        <p class="section-description">è©³ç´°ãªçµã‚Šè¾¼ã¿ã¯ã€ãƒšãƒ¼ã‚¸ä¸‹éƒ¨ã®ã‚¿ã‚°ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚</p>
        <div class="product-grid">
            {products_html}
        </div>
    </div>
</main>
"""
        header, footer = generate_header_footer(page_path, page_title=f"{main_cat}ã®å•†å“ä¸€è¦§")
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + main_content_html + footer)
        print(f"category/{main_cat}/index.html ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")

    # --- ç‰¹åˆ¥ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆå‹•çš„ãŠå¾—æƒ…å ±ï¼‰ã®ãƒšãƒ¼ã‚¸ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ ---
    # ã“ã“ãŒã”è¦æœ›ã®ã€Œãƒã‚¤ãƒ³ãƒˆç‰¹åŒ–ã€ã¨ã€ŒæœŸé–“é™å®šã‚»ãƒ¼ãƒ«ã€ã®é™çš„ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆã™ã‚‹éƒ¨åˆ†ã§ã™ã€‚
    
    special_categories = {
        'æœ€å®‰å€¤': sorted([p for p in products], key=lambda x: int(x.get('price', 0))),
        'æœŸé–“é™å®šã‚»ãƒ¼ãƒ«': [p for p in products if p.get('tags', []) and any(tag in ['ã‚»ãƒ¼ãƒ«', 'æœŸé–“é™å®š', 'ã‚¿ã‚¤ãƒ ã‚»ãƒ¼ãƒ«', 'ç‰¹ä¾¡'] for tag in p['tags'])],
        'ãƒã‚¤ãƒ³ãƒˆç‰¹åŒ–': [p for p in products if any(keyword in p.get('ai_headline', '') or keyword in p.get('ai_analysis', '') for keyword in ['ãƒã‚¤ãƒ³ãƒˆ', 'é‚„å…ƒç‡', 'ãŠå¾—', 'UP'])],
    }

    for special_cat, filtered_products in special_categories.items():
        page_path = f"category/{special_cat}/index.html"
        os.makedirs(os.path.dirname(page_path) or '.', exist_ok=True)
        products_html = "".join([generate_product_card_html(p, page_path) for p in filtered_products])
        
        if special_cat == 'ãƒã‚¤ãƒ³ãƒˆç‰¹åŒ–':
            title = "âœ¨AIãŒé¸ã‚“ã ãƒã‚¤ãƒ³ãƒˆé«˜é‚„å…ƒå•†å“"
            description = "AIãŒä¾¡æ ¼åˆ†æã®çµæœã€ã€Œãƒã‚¤ãƒ³ãƒˆé‚„å…ƒç‡ãŒé«˜ã„ã€ã€Œãƒã‚¤ãƒ³ãƒˆãŒãŠå¾—ã€ã¨åˆ¤æ–­ã—ãŸå•†å“ã‚’ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¦ã„ã¾ã™ã€‚è²·ã„æ™‚ã‚’è¦‹é€ƒã•ãªã„ã§ãã ã•ã„ï¼"
        elif special_cat == 'æœŸé–“é™å®šã‚»ãƒ¼ãƒ«':
            title = "ğŸ”¥é™å®šä¾¡æ ¼ï¼ä»Šã™ãè²·ã„ãŸã„ã‚»ãƒ¼ãƒ«å•†å“"
            description = "AIãŒã‚¿ã‚°ã‚„ä¾¡æ ¼å¤‰å‹•ã‚’åˆ†æã—ã€ç¾åœ¨ã‚»ãƒ¼ãƒ«ä¸­ãƒ»ã‚¿ã‚¤ãƒ ã‚»ãƒ¼ãƒ«ä¸­ã®å•†å“ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ã„ã¾ã™ã€‚"
        else:
            title = f"{special_cat}ã®ãŠå¾—ãªå•†å“ä¸€è¦§"
            description = f"{special_cat}ã®å•†å“ã‚’ä¸€è¦§ã§è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚"
            
        main_content_html = f"""
<main class="container">
    <div class="ai-recommendation-section">
        <h2 class="ai-section-title">{title}</h2>
        <p class="section-description">{description}</p>
        <div class="product-grid">
            {products_html}
        </div>
    </div>
</main>
"""
        header, footer = generate_header_footer(page_path, page_title=title)
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + main_content_html + footer)
        print(f"category/{special_cat}/index.html ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")

    # --- ç‰¹åˆ¥ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆå‹•çš„ãŠå¾—æƒ…å ±ï¼‰ã®ãƒšãƒ¼ã‚¸ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ çµ‚ ---


    # ã‚¿ã‚°ã”ã¨ã®ãƒšãƒ¼ã‚¸ç”Ÿæˆ
    all_tags = sorted(list(set(tag for product in products for tag in product.get('tags', []))))
    for tag in all_tags:
        safe_tag_name = tag.replace('/', '_').replace('\\', '_')
        
        tagged_products = [p for p in products if tag in p.get('tags', [])]
        tag_path = f"tags/{safe_tag_name}.html"
        
        products_html = "".join([generate_product_card_html(p, tag_path) for p in tagged_products])
        main_content_html = f"""
<main class="container">
    <div class="ai-recommendation-section">
        <h2 class="ai-section-title">#{tag}ã®æ³¨ç›®å•†å“</h2>
        <div class="product-grid">
            {products_html}
        </div>
    </div>
</main>
"""
        header, footer = generate_header_footer(tag_path, page_title=f"ã‚¿ã‚°ï¼š#{tag}")
        with open(tag_path, 'w', encoding='utf-8') as f:
            f.write(header + main_content_html + footer)
        print(f"{tag_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")

    # ã‚¿ã‚°ä¸€è¦§ãƒšãƒ¼ã‚¸ã®ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
    TAGS_PER_PAGE = 50
    total_tag_pages = math.ceil(len(all_tags) / TAGS_PER_PAGE)
    for i in range(total_tag_pages):
        start_index = i * TAGS_PER_PAGE
        end_index = start_index + PRODUCTS_PER_PAGE
        paginated_tags = all_tags[start_index:end_index]
        page_num = i + 1
        page_path = 'tags/index.html' if page_num == 1 else f'tags/page{page_num}.html'

        # ä¿®æ­£: æ–‡å­—åˆ—é€£çµã§å®‰å…¨ã«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ
        tag_links_html = "".join([
            f'<a href="{os.path.relpath("tags/" + t.replace("/", "_").replace(chr(92), "_") + ".html", os.path.dirname(page_path))}" class="tag-button">#{t}</a>'
            for t in paginated_tags
        ])

        pagination_html = ""
        if total_tag_pages > 1:
            pagination_html += '<div class="pagination">'
            if page_num > 1:
                prev_link = 'index.html' if page_num == 2 else f'page{page_num - 1}.html'
                pagination_html += f'<a href="{prev_link}" class="prev">å‰ã¸</a>'
            for p in range(1, total_tag_pages + 1):
                page_link = 'index.html' if p == 1 else f'page{p}.html'
                active_class = 'active' if p == page_num else ''
                pagination_html += f'<a href="{page_link}" class="{active_class}">{p}</a>'
            if page_num < total_tag_pages:
                next_link = f'page{page_num + 1}.html'
                pagination_html += f'<a href="{next_link}" class="next">æ¬¡ã¸</a>'
            pagination_html += '</div>'

        main_content_html = f"""
<main class="container">
    <div class="ai-recommendation-section">
        <h2 class="ai-section-title">ã‚¿ã‚°ã‹ã‚‰æ¢ã™</h2>
        <div class="product-tags all-tags-list">
            {tag_links_html}
        </div>
        {pagination_html}
    </div>
</main>
"""
        header, footer = generate_header_footer(page_path, page_title="ã‚¿ã‚°ã‹ã‚‰æ¢ã™")
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + main_content_html + footer)
        print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
        
    # å•†å“è©³ç´°ãƒšãƒ¼ã‚¸ã®ç”Ÿæˆ
    for product in products:
        page_path = product['page_url']
        dir_name = os.path.dirname(page_path)
        if dir_name:
            os.makedirs(dir_name, exist_ok=True)
        
        header, footer = generate_header_footer(page_path, page_title=f"{product.get('name', 'å•†å“å')}ã®è²·ã„æ™‚æƒ…å ±")
        
        ai_analysis_block_html = f"""
<div class="ai-analysis-block">
    <div class="ai-analysis-text">
        <h2>AIã«ã‚ˆã‚‹è²·ã„æ™‚åˆ†æ</h2>
        <p>{product.get('ai_analysis', 'è©³ç´°ãªAIåˆ†æã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚')}</p>
    </div>
</div>
"""
        price_history_for_chart = product.get('price_history', [])
        if not price_history_for_chart:
            try:
                price_int = int(str(product['price']).replace(',', ''))
                price_history_for_chart = [{"date": date.today().isoformat(), "price": price_int}]
            except (ValueError, KeyError):
                price_history_for_chart = []
        price_history_json = json.dumps(price_history_for_chart)
        price_chart_html = f"""
<div class="price-chart-section">
    <h2>ä¾¡æ ¼æ¨ç§»ã‚°ãƒ©ãƒ•</h2>
    <canvas id="priceChart" data-history='{price_history_json}'></canvas>
</div>
"""
        specs_html = f"""
<div class="item-specs">
    <h2>è£½å“ä»•æ§˜ãƒ»ã‚¹ãƒšãƒƒã‚¯</h2>
    <p>{product.get('specs', '')}</p>
</div>
""" if "specs" in product else ""

        # Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã®ãƒªãƒ³ã‚¯ã‚’ä¿®æ­£
        yahoo_affiliate_link = YAHOO_AFFILIATE_LINK

        affiliate_links_html = f"""
<div class="lowest-price-section">
    <p class="lowest-price-label">æœ€å®‰å€¤ã‚·ãƒ§ãƒƒãƒ—ã‚’ãƒã‚§ãƒƒã‚¯ï¼</p>
    <div class="lowest-price-buttons">
        <a href="{AMAZON_AFFILIATE_LINK}" class="btn shop-link amazon" target="_blank">Amazonã§è¦‹ã‚‹</a>
        <a href="{product.get("rakuten_url", "https://www.rakuten.co.jp/")}" class="btn shop-link rakuten" target="_blank">æ¥½å¤©å¸‚å ´ã§è¦‹ã‚‹</a>
        <a href="{yahoo_affiliate_link}" class="btn shop-link yahoo" rel="nofollow" target="_blank">Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã§è¦‹ã‚‹</a>
    </div>
</div>
"""
        
        # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®ç›¸å¯¾ãƒ‘ã‚¹ã‚’è¨ˆç®—
        rel_path_to_root = os.path.relpath('.', os.path.dirname(page_path))
        if rel_path_to_root == '.':
            base_path = './'
        else:
            base_path = rel_path_to_root + '/'

        item_html_content = f"""
<main class="container">
    <div class="product-detail">
        <div class="item-detail">
            <div class="item-image">
                <img src="{product.get('image_url', '')}" alt="{product.get('name', 'å•†å“ç”»åƒ')}" class="main-product-image">
            </div>
            <div class="item-info">
                <h1 class="item-name">{product.get('name', 'å•†å“å')}</h1>
                <!-- ãƒ‘ãƒ³ããšãƒªã‚¹ãƒˆã‚’å‰Šé™¤ -->
                <div class="price-section">
                    <p class="current-price">ç¾åœ¨ã®ä¾¡æ ¼ï¼š<span>{int(product.get('price', 0)):,}</span>å††</p>
                </div>
                <div class="ai-recommendation-section">
                    <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
                    <div class="price-status-content ai-analysis">{product.get('ai_headline', 'AIåˆ†ææº–å‚™ä¸­')}</div>
                    <div class="product-card-buttons-full">
                        <a href="{product.get("rakuten_url", "https://www.rakuten.co.jp/")}" class="btn shop-link rakuten" target="_blank">æ¥½å¤©å¸‚å ´ã§è³¼å…¥ã™ã‚‹</a>
                    </div>
                </div>
                {affiliate_links_html}
                {ai_analysis_block_html}
                {price_chart_html}
                <div class="item-description">
                    <h2>AIã«ã‚ˆã‚‹å•†å“ãƒã‚¤ãƒ©ã‚¤ãƒˆ</h2>
                    <p>{product.get('ai_summary', 'ã“ã®å•†å“ã®è©³ã—ã„èª¬æ˜ã¯æº–å‚™ä¸­ã§ã™ã€‚')}</p>
                </div>
                {specs_html}
                <div class="product-tags">
                    {"".join([f'<a href="{base_path}tags/{tag.replace("/", "_").replace(chr(92), "_")}.html" class="tag-button">#{tag}</a>' for tag in product.get("tags", [])])}
                </div>
            </div>
        </div>
    </div>
</main>
"""
        with open(page_path, 'w', encoding='utf-8') as f:
            f.write(header + item_html_content + footer)
        print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
        
    # sitemap.xmlã®ç”Ÿæˆ
    sitemap_content = '<?xml version="1.0" encoding="UTF-8"?>\n'
    sitemap_content += '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'
    base_url = "https://your-website.com/"
    sitemap_urls = [
        (base_url, 'daily', '1.0'),
        (f'{base_url}privacy.html', 'monthly', '0.5'),
        (f'{base_url}disclaimer.html', 'monthly', '0.5'),
        (f'{base_url}contact.html', 'monthly', '0.5'),
        (f'{base_url}search_results.html', 'daily', '0.5'),
        (f'{base_url}ai_search.html', 'weekly', '0.7') # AIã§æ¢ã™ã®ãƒšãƒ¼ã‚¸ã‚’è¿½åŠ 
    ]

    for product in products:
        sitemap_urls.append((f'{base_url}{product.get("page_url", "")}', 'daily', '0.6'))
    
    total_pages = math.ceil(len(products) / PRODUCTS_PER_PAGE)
    for i in range(2, total_pages + 1):
        sitemap_urls.append((f'{base_url}pages/page{i}.html', 'daily', '0.8'))

    # ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒšãƒ¼ã‚¸ã‚’è¿½åŠ  (ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¯å‰Šé™¤)
    all_categories_sitemap = list(PRODUCT_CATEGORIES.keys()) + ['ãã®ä»–']
    for main_cat in all_categories_sitemap:
        # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®index.htmlã®ã¿è¿½åŠ 
        sitemap_urls.append((f'{base_url}category/{main_cat}/index.html', 'daily', '0.8'))
    
    # ç‰¹åˆ¥ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆå‹•çš„ãŠå¾—æƒ…å ±ï¼‰ã‚‚è¿½åŠ 
    for special_cat in ['æœ€å®‰å€¤', 'æœŸé–“é™å®šã‚»ãƒ¼ãƒ«', 'ãƒã‚¤ãƒ³ãƒˆç‰¹åŒ–']:
        sitemap_urls.append((f'{base_url}category/{special_cat}/index.html', 'daily', '0.8'))

    # ã‚¿ã‚°ãƒšãƒ¼ã‚¸ã‚’è¿½åŠ 
    all_tags_sitemap = sorted(list(set(tag for product in products for tag in product.get('tags', []))))
    sitemap_urls.append((f'{base_url}tags/index.html', 'weekly', '0.7')) # ã‚¿ã‚°ä¸€è¦§ãƒšãƒ¼ã‚¸
    for tag in all_tags_sitemap:
        safe_tag_name = tag.replace("/", "_").replace("\\", "_")
        sitemap_urls.append((f'{base_url}tags/{safe_tag_name}.html', 'daily', '0.6'))
    
    total_tag_pages_sitemap = math.ceil(len(all_tags_sitemap) / TAGS_PER_PAGE)
    for i in range(2, total_tag_pages_sitemap + 1):
        sitemap_urls.append((f'{base_url}tags/page{i}.html', 'daily', '0.6'))

    for url, changefreq, priority in sitemap_urls:
        sitemap_content += '  <url>\n'
        sitemap_content += f'    <loc>{url}</loc>\n'
        sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
        sitemap_content += f'    <changefreq>{changefreq}</changefreq>\n'
        sitemap_content += f'    <priority>{priority}</priority>\n'
        sitemap_content += '  </url>\n'
    
    sitemap_content += '</urlset>'
    with open('sitemap.xml', 'w', encoding='utf-8') as f:
        f.write(sitemap_content)
    print("sitemap.xmlãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")

# æ¤œç´¢ç”¨JSONã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
def generate_search_index(products):
    """JavaScriptãŒæ¤œç´¢ã«ä½¿ç”¨ã™ã‚‹ãŸã‚ã®JSONãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹"""
    try:
        search_data = []
        for p in products:
            # æ¤œç´¢å¯¾è±¡ã¨ãªã‚‹æƒ…å ±ã‚’ã²ã¨ã¤ã®æ–‡å­—åˆ—ã«ã¾ã¨ã‚ã‚‹
            search_text = f"{p['name']} {p.get('description', '')} {' '.join(p.get('tags', []))} {p.get('category', {}).get('main', '')} {p.get('category', {}).get('sub', '')}"
            
            search_data.append({
                "id": p['id'],
                "name": p['name'],
                "page_url": p['page_url'],
                "image_url": p['image_url'],
                "price": p['price'],
                "ai_headline": p.get('ai_headline', ''),
                "searchable_text": search_text.lower() # æ¤œç´¢ã‚’åŠ¹ç‡åŒ–ã™ã‚‹ãŸã‚ã€å°æ–‡å­—ã§ä¿å­˜
            })
            
        with open('search_index.json', 'w', encoding='utf-8') as f:
            json.dump(search_data, f, ensure_ascii=False, indent=2)
        print("search_index.json ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"æ¤œç´¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# æ¤œç´¢çµæœãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
def generate_search_results_page():
    """æ¤œç´¢çµæœãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
    page_path = "search_results.html"
    header, footer = generate_header_footer(page_path, page_title="æ¤œç´¢çµæœ")

    # æ¤œç´¢çµæœã¯JavaScriptã§å‹•çš„ã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã€ç©ºã®ã‚³ãƒ³ãƒ†ãƒŠã‚’ç”¨æ„
    main_content_html = """
<main class="container">
    <div class="ai-recommendation-section">
        <h2 class="ai-section-title">æ¤œç´¢çµæœ</h2>
        <div id="search-results-container" class="product-grid">
            <p id="loading-message">æ¤œç´¢ä¸­ã§ã™...</p>
            </div>
    </div>
</main>
"""
    with open(page_path, 'w', encoding='utf-8') as f:
        f.write(header + main_content_html + footer)
    print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")

def main():
    new_products = fetch_rakuten_items()
    final_products = update_products_csv(new_products)

    generate_search_index(final_products)
    generate_search_results_page()

    # AIã§æ¢ã™ã€ãƒã‚¤ãƒ³ãƒˆç‰¹åŒ–ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ
    generate_placeholder_page("ai_search.html", "AIã§æ¢ã™", "AIãŒãŠã™ã™ã‚ã™ã‚‹å•†å“ã‚’è¦‹ã¤ã‘ã‚ˆã†ï¼")
    # ãƒã‚¤ãƒ³ãƒˆç‰¹åŒ–ã¨æœŸé–“é™å®šã‚»ãƒ¼ãƒ«ã¯ã€generate_site é–¢æ•°å†…ã§å‹•çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ã—ã¦ç”Ÿæˆã•ã‚Œã‚‹ãŒã€
    # å‡¦ç†ãƒ•ãƒ­ãƒ¼ã®ãŸã‚ã«ã“ã“ã§ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚‚ç”Ÿæˆã—ã¦ãŠã

    generate_site(final_products)

def generate_placeholder_page(page_path, title, description):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆã™ã‚‹"""
    os.makedirs(os.path.dirname(page_path) or '.', exist_ok=True)
    header, footer = generate_header_footer(page_path, page_title=title)
    main_content_html = f"""
<main class="container">
    <div class="ai-recommendation-section">
        <h2 class="ai-section-title">{title}</h2>
        <p class="section-description">{description}</p>
        <p style="text-align: center; margin-top: 50px;">ã“ã®ãƒšãƒ¼ã‚¸ã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚ä»–ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚„ã‚¿ã‚°ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚</p>
    </div>
</main>
"""
    with open(page_path, 'w', encoding='utf-8') as f:
        f.write(header + main_content_html + footer)
    print(f"{page_path} (ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼) ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")


if __name__ == '__main__':
    main()
