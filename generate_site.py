import json
import math
import os
import shutil
from datetime import date
import requests
from openai import OpenAI

# å®šæ•°å®šç¾©
PRODUCTS_PER_PAGE = 24
TAGS_PER_PAGE = 50
BASE_URL = "https://w41w41-beep.github.io/kaidoki-navi/"

# æ¥½å¤©ã®ã‚¸ãƒ£ãƒ³ãƒ«IDã¨ã‚µã‚¤ãƒˆã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å®šç¾©
RAKUTEN_GENRE_MAP = {
    # å®¶é›»
    "æƒé™¤æ©Ÿ": {
        "main": "å®¶é›»",
        "sub": "æƒé™¤æ©Ÿ",
        "ids": ["212871", "562768"] # æƒé™¤æ©Ÿãƒ»ã‚¯ãƒªãƒ¼ãƒŠãƒ¼ã€ãƒ­ãƒœãƒƒãƒˆæƒé™¤æ©Ÿ
    },
    "ç©ºæ°—æ¸…æµ„æ©Ÿ": {
        "main": "å®¶é›»",
        "sub": "ç©ºæ°—æ¸…æµ„æ©Ÿ",
        "ids": ["210214"] # ç©ºæ°—æ¸…æµ„æ©Ÿ
    },
    "ã‚¨ã‚¢ã‚³ãƒ³": {
        "main": "å®¶é›»",
        "sub": "ã‚¨ã‚¢ã‚³ãƒ³",
        "ids": ["100032"] # ã‚¨ã‚¢ã‚³ãƒ³
    },
    "å†·è”µåº«": {
        "main": "å®¶é›»",
        "sub": "å†·è”µåº«",
        "ids": ["100259"] # å†·è”µåº«
    },
    "é›»å­ãƒ¬ãƒ³ã‚¸": {
        "main": "å®¶é›»",
        "sub": "é›»å­ãƒ¬ãƒ³ã‚¸",
        "ids": ["100262"] # é›»å­ãƒ¬ãƒ³ã‚¸ãƒ»ã‚ªãƒ¼ãƒ–ãƒ³ãƒ¬ãƒ³ã‚¸
    },
    
    # ãƒ‘ã‚½ã‚³ãƒ³ãƒ»å‘¨è¾ºæ©Ÿå™¨
    "ãƒãƒ¼ãƒˆPC": {
        "main": "ãƒ‘ã‚½ã‚³ãƒ³",
        "sub": "ãƒãƒ¼ãƒˆPC",
        "ids": ["562629"] # ãƒãƒ¼ãƒˆPC
    },
    "ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—PC": {
        "main": "ãƒ‘ã‚½ã‚³ãƒ³",
        "sub": "ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—PC",
        "ids": ["562630"] # ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—PC
    },
    "ãƒ¢ãƒ‹ã‚¿ãƒ¼": {
        "main": "ãƒ‘ã‚½ã‚³ãƒ³",
        "sub": "ãƒ¢ãƒ‹ã‚¿ãƒ¼",
        "ids": ["200109"] # ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤
    },
    "ãƒ—ãƒªãƒ³ã‚¿ãƒ¼": {
        "main": "ãƒ‘ã‚½ã‚³ãƒ³",
        "sub": "ãƒ—ãƒªãƒ³ã‚¿ãƒ¼",
        "ids": ["100277"] # ãƒ—ãƒªãƒ³ã‚¿
    },
    "å‘¨è¾ºæ©Ÿå™¨": {
        "main": "ãƒ‘ã‚½ã‚³ãƒ³",
        "sub": "å‘¨è¾ºæ©Ÿå™¨",
        "ids": ["200100", "200101", "200102"] # ãƒ‘ã‚½ã‚³ãƒ³å‘¨è¾ºæ©Ÿå™¨ã€ãƒã‚¦ã‚¹ãƒ»ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰
    }
}

# ãƒ¤ãƒ•ãƒ¼ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼IDã¨ã‚µã‚¤ãƒˆã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å®šç¾©
YAHOO_CATEGORY_MAP = {
    # å®¶é›»
    "æƒé™¤æ©Ÿ": {
        "main": "å®¶é›»",
        "sub": "æƒé™¤æ©Ÿ",
        "ids": ["12999"]
    },
    "ç©ºæ°—æ¸…æµ„æ©Ÿ": {
        "main": "å®¶é›»",
        "sub": "ç©ºæ°—æ¸…æµ„æ©Ÿ",
        "ids": ["12479"]
    },
    "ã‚¨ã‚¢ã‚³ãƒ³": {
        "main": "å®¶é›»",
        "sub": "ã‚¨ã‚¢ã‚³ãƒ³",
        "ids": ["2513"]
    },
    "å†·è”µåº«": {
        "main": "å®¶é›»",
        "sub": "å†·è”µåº«",
        "ids": ["12995"]
    },
    "é›»å­ãƒ¬ãƒ³ã‚¸": {
        "main": "å®¶é›»",
        "sub": "é›»å­ãƒ¬ãƒ³ã‚¸",
        "ids": ["12996"]
    },
    
    # ãƒ‘ã‚½ã‚³ãƒ³ãƒ»å‘¨è¾ºæ©Ÿå™¨
    "ãƒãƒ¼ãƒˆPC": {
        "main": "ãƒ‘ã‚½ã‚³ãƒ³",
        "sub": "ãƒãƒ¼ãƒˆPC",
        "ids": ["2502"]
    },
    "ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—PC": {
        "main": "ãƒ‘ã‚½ã‚³ãƒ³",
        "sub": "ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—PC",
        "ids": ["2502"]
    },
    "ãƒ¢ãƒ‹ã‚¿ãƒ¼": {
        "main": "ãƒ‘ã‚½ã‚³ãƒ³",
        "sub": "ãƒ¢ãƒ‹ã‚¿ãƒ¼",
        "ids": ["2505"]
    },
    "ãƒ—ãƒªãƒ³ã‚¿ãƒ¼": {
        "main": "ãƒ‘ã‚½ã‚³ãƒ³",
        "sub": "ãƒ—ãƒªãƒ³ã‚¿ãƒ¼",
        "ids": ["2508"]
    },
    "å‘¨è¾ºæ©Ÿå™¨": {
        "main": "ãƒ‘ã‚½ã‚³ãƒ³",
        "sub": "å‘¨è¾ºæ©Ÿå™¨",
        "ids": ["2507", "12984"] # ãƒã‚¦ã‚¹ã€ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰
    }
}

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = OpenAI(
    api_key=os.environ.get('OPENAI_API_KEY')
)

def generate_ai_info(item_name, item_description, item_category):
    """AIã‚’ä½¿ã£ã¦è£½å“ã‚¹ãƒšãƒƒã‚¯ã¨ã‚¿ã‚°ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
    prompt = f"""
ä»¥ä¸‹ã®å•†å“ã®æƒ…å ±ã‹ã‚‰ã€ä¸»ãªè£½å“ä»•æ§˜ï¼ˆã‚¹ãƒšãƒƒã‚¯ï¼‰ã‚’ç®‡æ¡æ›¸ãã§åˆ†ã‹ã‚Šã‚„ã™ãç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
ã¾ãŸã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¤œç´¢ã—ãã†ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’3ã€œ5å€‹ã€å˜èªã§æŠ½å‡ºã—ã¦ã€Œã‚¿ã‚°ã€ã¨ã—ã¦ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

å•†å“å: {item_name}
å•†å“èª¬æ˜: {item_description}
ã‚«ãƒ†ã‚´ãƒª: {item_category['main']} > {item_category['sub']}

---
å‡ºåŠ›å½¢å¼ï¼š
ã‚¹ãƒšãƒƒã‚¯ï¼š
- [ã‚¹ãƒšãƒƒã‚¯1]
- [ã‚¹ãƒšãƒƒã‚¯2]
- ...
ã‚¿ã‚°ï¼š
[ã‚¿ã‚°1], [ã‚¿ã‚°2], [ã‚¿ã‚°3], ...
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        content = response.choices[0].message.content.strip()
        
        # å‡ºåŠ›å½¢å¼ã‚’è§£æ
        specs_start = content.find("ã‚¹ãƒšãƒƒã‚¯ï¼š")
        tags_start = content.find("ã‚¿ã‚°ï¼š")
        
        specs_text = content[specs_start + len("ã‚¹ãƒšãƒƒã‚¯ï¼š"):tags_start].strip()
        tags_text = content[tags_start + len("ã‚¿ã‚°ï¼š"):].strip()
        
        specs_list = [line.lstrip('- ').strip() for line in specs_text.split('\n') if line.lstrip('- ').strip()]
        tags_list = [tag.strip() for tag in tags_text.split(',') if tag.strip()]
        
        return {
            "specs": "\n".join([f"ãƒ»{spec}" for spec in specs_list]),
            "tags": tags_list
        }

    except Exception as e:
        print(f"AIæƒ…å ±ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return {
            "specs": "AIã«ã‚ˆã‚‹è£½å“ä»•æ§˜ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚",
            "tags": []
        }

def fetch_rakuten_items():
    """æ¥½å¤©APIã‹ã‚‰è¤‡æ•°ã®ã‚«ãƒ†ã‚´ãƒªã§å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹é–¢æ•°"""
    app_id = os.environ.get('RAKUTEN_API_KEY')
    if not app_id:
        print("RAKUTEN_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return []

    all_products = []
    
    for cat_info in RAKUTEN_GENRE_MAP.values():
        main_cat = cat_info["main"]
        sub_cat = cat_info.get("sub", "")
        genre_ids = cat_info["ids"]
        
        for genre_id in genre_ids:
            url = f"https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706?applicationId={app_id}&genreId={genre_id}&format=json&sort=-reviewCount&hits=10"
            try:
                response = requests.get(url)
                response.raise_for_status()
                data = response.json()
                items = data.get('Items', [])
                
                for item in items:
                    item_data = item['Item']
                    
                    all_products.append({
                        "id": item_data['itemCode'],
                        "name": item_data['itemName'],
                        "price": f"{int(item_data['itemPrice']):,}",
                        "image_url": item_data['mediumImageUrls'][0]['imageUrl'],
                        "rakuten_url": item_data['itemUrl'],
                        "yahoo_url": "https://shopping.yahoo.co.jp/", 
                        "amazon_url": "https://www.amazon.co.jp/ref=as_li_ss_il?ie=UTF8&linkCode=ilc&tag=soc07-22&linkId=db3c1808e6f1f516353d266e76811a7c&language=ja_JP",
                        "page_url": f"pages/{item_data['itemCode']}.html",
                        "category": {
                            "main": main_cat,
                            "sub": sub_cat
                        },
                        "ai_analysis": "AIã«ã‚ˆã‚‹ä¾¡æ ¼åˆ†æã¯è¿‘æ—¥å…¬é–‹ï¼",
                        "description": item_data.get('itemCaption', 'å•†å“èª¬æ˜ã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚'),
                        "date": date.today().isoformat(),
                        "main_ec_site": "æ¥½å¤©"
                    })
            except requests.exceptions.RequestException as e:
                print(f"æ¥½å¤©APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    return all_products

def fetch_yahoo_items():
    """Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°APIã‹ã‚‰å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹é–¢æ•°"""
    app_id = os.environ.get('YAHOO_API_KEY')
    if not app_id:
        print("YAHOO_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return []

    all_products = []
    
    for cat_info in YAHOO_CATEGORY_MAP.values():
        main_cat = cat_info["main"]
        sub_cat = cat_info.get("sub", "")
        category_ids = cat_info["ids"]
        
        for category_id in category_ids:
            url = f"https://shopping.yahooapis.jp/ShoppingWebService/V3/itemSearch?appid={app_id}&category_id={category_id}&sort=-review_count&hits=5"
            try:
                response = requests.get(url)
                response.raise_for_status()
                data = response.json()
                items = data.get('hits', [])
                
                for item in items:
                    all_products.append({
                        "id": item['jan_code'],
                        "name": item['name'],
                        "price": f"{int(item['price']):,}",
                        "image_url": item['image']['medium'],
                        "rakuten_url": "https://www.rakuten.co.jp/",
                        "yahoo_url": item['url'],
                        "amazon_url": "https://www.amazon.co.jp/ref=as_li_ss_il?ie=UTF8&linkCode=ilc&tag=soc07-22&linkId=db3c1808e6f1f516353d266e76811a7c&language=ja_JP",
                        "page_url": f"pages/{item['jan_code']}.html",
                        "category": {
                            "main": main_cat,
                            "sub": sub_cat
                        },
                        "ai_analysis": "AIã«ã‚ˆã‚‹ä¾¡æ ¼åˆ†æã¯è¿‘æ—¥å…¬é–‹ï¼",
                        "description": item.get('description', 'å•†å“èª¬æ˜ã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚'),
                        "date": date.today().isoformat(),
                        "main_ec_site": "Yahoo!"
                    })
            except requests.exceptions.RequestException as e:
                print(f"Yahoo! APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            
    return all_products

def update_products_json(new_products):
    """æ–°ã—ã„å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æ—¢å­˜ã®products.jsonã«çµ±åˆãƒ»æ›´æ–°ã™ã‚‹é–¢æ•°"""
    try:
        if os.path.exists('products.json'):
            with open('products.json', 'r', encoding='utf-8') as f:
                existing_products = json.load(f)
        else:
            existing_products = []
    except json.JSONDecodeError:
        print("products.jsonãŒç ´æã—ã¦ã„ã‚‹ãŸã‚ã€æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
        existing_products = []

    updated_products = {p['id']: p for p in existing_products}
    
    # æ–°ã—ã„å•†å“æƒ…å ±ã‚’AIã§ç”Ÿæˆã—ã¦è¿½åŠ 
    for new_product in new_products:
        ai_info = generate_ai_info(
            item_name=new_product['name'],
            item_description=new_product['description'],
            item_category=new_product['category']
        )
        new_product['specs'] = ai_info['specs']
        new_product['tags'] = ai_info['tags']
        updated_products[new_product['id']] = new_product
    
    final_products = list(updated_products.values())
    
    with open('products.json', 'w', encoding='utf-8') as f:
        json.dump(final_products, f, ensure_ascii=False, indent=4)
    
    print(f"products.jsonãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸã€‚ç¾åœ¨ {len(final_products)} å€‹ã®å•†å“ã‚’è¿½è·¡ä¸­ã§ã™ã€‚")
    return final_products

def generate_site(products):
    """products.jsonã‚’èª­ã¿è¾¼ã¿ã€HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
    today = date.today().isoformat()
    for product in products:
        if 'date' not in product:
            product['date'] = today
    products.sort(key=lambda p: p['date'], reverse=True)
    
    categories = {}
    for product in products:
        main_cat = product['category']['main']
        sub_cat = product['category']['sub']
        if main_cat not in categories:
            categories[main_cat] = set()
        if sub_cat:
            categories[main_cat].add(sub_cat)

    sorted_main_cats = sorted(categories.keys())

    # ã‚µã‚¤ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    for root, dirs, files in os.walk('.'):
        for file in files:
            if file.endswith('.html') and not file in ['privacy.html', 'disclaimer.html', 'contact.html']:
                os.remove(os.path.join(root, file))
    if os.path.exists('category'):
        shutil.rmtree('category')
    if os.path.exists('pages'):
        shutil.rmtree('pages')
    if os.path.exists('tags'):
        shutil.rmtree('tags')

    def _get_base_path(current_path):
        """ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã®ãƒ‘ã‚¹ã‹ã‚‰ç›¸å¯¾ãƒ‘ã‚¹ã‚’è¨ˆç®—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
        depth = current_path.count('/')
        return "../" * depth if depth > 0 else "."

    def _generate_header_footer(current_path, sub_cat_links=None, page_title="ãŠå¾—ãªè²·ã„æ™‚ã‚’è¦‹ã¤ã‘ã‚ˆã†ï¼"):
        """ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ãƒ•ãƒƒã‚¿ãƒ¼ã®HTMLã‚’ç”Ÿæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
        base_path = _get_base_path(current_path)
        main_links_html = f'<a href="{base_path}/tags/index.html">ã‚¿ã‚°ã‹ã‚‰æ¢ã™</a><span class="separator">|</span>'
        for mc_link in sorted_main_cats:
            main_links_html += f'<a href="{base_path}/category/{mc_link}/index.html">{mc_link}</a><span class="separator">|</span>'
        header_html = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“ | {page_title}</title>
    <link rel="stylesheet" href="{base_path}/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <meta name="google-site-verification" content="OmUuOjcxi7HXBKe47sd0WPbzCfbCOFbPj_iueHBk2qo" />
</head>
<body>
    <header>
        <div class="container">
            <h1><a href="{base_path}/index.html">ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“</a></h1>
            <p>ãŠå¾—ãªè²·ã„æ™‚ã‚’è¦‹ã¤ã‘ã‚ˆã†ï¼</p>
        </div>
    </header>

    <div class="search-bar">
        <div class="search-container">
            <input type="text" placeholder="å•†å“åã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢...">
            <button class="search-button">ğŸ”</button>
        </div>
    </div>

    <div class="genre-links-container">
        <div class="genre-links">
            {main_links_html}
        </div>
    </div>
"""
        sub_cat_links_html = ""
        if sub_cat_links:
            sub_cat_links_html += '<div class="genre-links sub-genre-links">'
            for sub_cat_link in sorted(list(sub_cat_links)):
                sub_cat_links_html += f'<a href="{sub_cat_link.replace(" ", "")}.html">{sub_cat_link}</a><span class="separator">|</span>'
            sub_cat_links_html += '</div>'
            header_html += f"""
    <div class="sub-genre-links-container">
        {sub_cat_links_html}
    </div>
"""
        footer_html = f"""
    </main>
    <footer>
        <p>&copy; 2025 ã‚«ã‚¤ãƒ‰ã‚­-ãƒŠãƒ“. All Rights Reserved.</p>
        <div class="footer-links">
            <a href="{base_path}/privacy.html">ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼</a>
            <a href="{base_path}/disclaimer.html">å…è²¬äº‹é …</a>
            <a href="{base_path}/contact.html">ãŠå•ã„åˆã‚ã›</a>
        </div>
    </footer>
    <script src="{base_path}/script.js"></script>
</body>
</html>
        """
        return header_html, footer_html

    def _generate_product_card_html(product, current_path):
        """å•†å“ã‚«ãƒ¼ãƒ‰ã®HTMLã‚’ç”Ÿæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
        link_path = os.path.relpath(product['page_url'], os.path.dirname(current_path))
        return f"""
<a href="{link_path}" class="product-card">
    <img src="{product['image_url']}" alt="{product['name']}">
    <div class="product-info">
        <h3 class="product-name">{product['name'][:20] + '...' if len(product['name']) > 20 else product['name']}</h3>
        <p class="product-price">{product['price']}å††</p>
        <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
        <div class="price-status-content ai-analysis">{product['ai_analysis']}</div>
    </div>
</a>
"""

    def _generate_index_pages(products):
        """ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã¨ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
        total_pages = math.ceil(len(products) / PRODUCTS_PER_PAGE)
        for i in range(total_pages):
            start_index = i * PRODUCTS_PER_PAGE
            end_index = start_index + PRODUCTS_PER_PAGE
            paginated_products = products[start_index:end_index]
            page_num = i + 1
            page_path = 'index.html' if page_num == 1 else f'pages/page{page_num}.html'
            if page_num > 1:
                os.makedirs(os.path.dirname(page_path), exist_ok=True)
            
            header, footer = _generate_header_footer(page_path)
            
            products_html = "".join([_generate_product_card_html(p, page_path) for p in paginated_products])
            
            pagination_html = ""
            if total_pages > 1:
                pagination_html += '<div class="pagination">'
                if page_num > 1:
                    prev_link = 'index.html' if page_num == 2 else f'pages/page{page_num - 1}.html'
                    pagination_html += f'<a href="{os.path.relpath(prev_link, os.path.dirname(page_path))}" class="prev">å‰ã¸</a>'
                for p in range(1, total_pages + 1):
                    page_link = 'index.html' if p == 1 else f'pages/page{p}.html'
                    active_class = 'active' if p == page_num else ''
                    pagination_html += f'<a href="{os.path.relpath(page_link, os.path.dirname(page_path))}" class="{active_class}">{p}</a>'
                if page_num < total_pages:
                    next_link = f'pages/page{page_num + 1}.html'
                    pagination_html += f'<a href="{os.path.relpath(next_link, os.path.dirname(page_path))}" class="next">æ¬¡ã¸</a>'
                pagination_html += '</div>'
            
            with open(page_path, 'w', encoding='utf-8') as f:
                f.write(header + '<main class="container"><div class="ai-recommendation-section"><h2 class="ai-section-title">ä»ŠãŒè²·ã„æ™‚ï¼ãŠå¾—ãªæ³¨ç›®ã‚¢ã‚¤ãƒ†ãƒ </h2><div class="product-grid">' + products_html + '</div>' + pagination_html + '</main>' + footer)
            print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    def _generate_category_pages(products, categories):
        """ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
        for main_cat, sub_cats in categories.items():
            main_cat_products = [p for p in products if p['category']['main'] == main_cat]
            page_path = f"category/{main_cat}/index.html"
            os.makedirs(os.path.dirname(page_path), exist_ok=True)
            header, footer = _generate_header_footer(page_path, sub_cat_links=sub_cats, page_title=f"{main_cat}ã®å•†å“ä¸€è¦§")
            main_content_html = f"""
    <main class="container">
        <div class="ai-recommendation-section">
            <h2 class="ai-section-title">{main_cat}ã®å•†å“ä¸€è¦§</h2>
            <div class="product-grid">
            """
            products_html = "".join([_generate_product_card_html(p, page_path) for p in main_cat_products])
            with open(page_path, 'w', encoding='utf-8') as f:
                f.write(header + main_content_html + products_html + "</div></div>" + footer)
            print(f"category/{main_cat}/index.html ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
            
            for sub_cat in sub_cats:
                sub_cat_products = [p for p in products if p['category']['sub'] == sub_cat]
                sub_cat_file_name = f"{sub_cat.replace(' ', '')}.html"
                page_path = f"category/{main_cat}/{sub_cat_file_name}"
                header, footer = _generate_header_footer(page_path, page_title=f"{sub_cat}ã®å•†å“ä¸€è¦§")
                main_content_html = f"""
    <main class="container">
        <div class="ai-recommendation-section">
            <h2 class="ai-section-title">{sub_cat}ã®å•†å“ä¸€è¦§</h2>
            <div class="product-grid">
            """
                products_html = "".join([_generate_product_card_html(p, page_path) for p in sub_cat_products])
                with open(page_path, 'w', encoding='utf-8') as f:
                    f.write(header + main_content_html + products_html + "</div></div>" + footer)
                print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")

    def _generate_product_detail_pages(products):
        """å€‹åˆ¥å•†å“ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
        for product in products:
            page_path = product['page_url']
            dir_name = os.path.dirname(page_path)
            if dir_name:
                os.makedirs(dir_name, exist_ok=True)
            
            header, footer = _generate_header_footer(page_path, page_title=f"{product['name']}ã®è²·ã„æ™‚æƒ…å ±")
            
            ai_analysis_block_html = """
            <div class="ai-analysis-block">
                <div class="ai-analysis-text">
                    <h2>AIã«ã‚ˆã‚‹è²·ã„æ™‚åˆ†æ</h2>
                    <p>ä¾¡æ ¼æ¨ç§»ã‚°ãƒ©ãƒ•ã¨AIã«ã‚ˆã‚‹è©³ç´°åˆ†æã‚’è¿‘æ—¥å…¬é–‹ï¼ä¹ã†ã”æœŸå¾…ï¼</p>
                </div>
            </div>
            """
            specs_html = ""
            if "specs" in product:
                specs_html = f"""
                <div class="item-specs">
                    <h2>è£½å“ä»•æ§˜ãƒ»ã‚¹ãƒšãƒƒã‚¯</h2>
                    <p>{product.get('specs', '')}</p>
                </div>
                """
            
            purchase_button_html = ""
            main_ec_site = product.get("main_ec_site")
            if main_ec_site == "Amazon":
                purchase_button_html = f'<a href="{product["amazon_url"]}" class="purchase-button" target="_blank">Amazonã§è³¼å…¥ã™ã‚‹</a>'
            elif main_ec_site == "æ¥½å¤©":
                purchase_button_html = f'<a href="{product["rakuten_url"]}" class="purchase-button" target="_blank">æ¥½å¤©å¸‚å ´ã§è³¼å…¥ã™ã‚‹</a>'
            elif main_ec_site == "Yahoo!":
                purchase_button_html = f'<a href="{product["yahoo_url"]}" class="purchase-button" target="_blank">Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã§è³¼å…¥ã™ã‚‹</a>'
            
            affiliate_links_html = f"""
            <div class="lowest-price-section">
                <p class="lowest-price-label">æœ€å®‰å€¤ã‚·ãƒ§ãƒƒãƒ—ã‚’ãƒã‚§ãƒƒã‚¯ï¼</p>
                <div class="lowest-price-buttons">
                    <a href="{product.get("amazon_url", "https://www.amazon.co.jp/")}" class="btn shop-link" target="_blank">Amazonã§è¦‹ã‚‹</a>
                    <a href="{product.get("rakuten_url", "https://www.rakuten.co.jp/")}" class="btn shop-link" target="_blank">æ¥½å¤©å¸‚å ´ã§è¦‹ã‚‹</a>
                    <a href="{product.get("yahoo_url", "https://shopping.yahoo.co.jp/")}" class="btn shop-link" target="_blank">Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã§è¦‹ã‚‹</a>
                </div>
            </div>
            """
            item_html_content = f"""
<main class="container">
    <div class="product-detail">
        <div class="item-detail">
            <div class="item-image">
                <img src="{product['image_url']}" alt="{product['name']}" class="main-product-image">
            </div>
            <div class="item-info">
                <h1 class="item-name">{product['name']}</h1>
                <p class="item-category">ã‚«ãƒ†ã‚´ãƒªï¼š<a href="{os.path.relpath('category/' + product['category']['main'] + '/index.html', os.path.dirname(page_path))}">{product['category']['main']}</a> &gt;
                <a href="{os.path.relpath('category/' + product['category']['main'] + '/' + product['category']['sub'].replace(' ', '') + '.html', os.path.dirname(page_path))}">{product['category']['sub']}</a></p>
                <div class="price-section">
                    <p class="current-price">ç¾åœ¨ã®ä¾¡æ ¼ï¼š<span>{product['price']}å††</span></p>
                </div>
                <div class="ai-recommendation-section">
                    <div class="price-status-title">ğŸ’¡æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ</div>
                    <div class="price-status-content ai-analysis">{product['ai_analysis']}</div>
                    {purchase_button_html}
                </div>
                {ai_analysis_block_html}
                {affiliate_links_html}
                <div class="item-description">
                    <h2>å•†å“èª¬æ˜</h2>
                    <p>{product.get('description', 'å•†å“èª¬æ˜ã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚')}</p>
                </div>
                {specs_html}
                <div class="product-tags">
                    {"".join([f'<a href="{os.path.relpath("tags/" + tag.replace(" ", "") + ".html", os.path.dirname(page_path))}" class="tag-button">#{tag}</a>' for tag in product.get('tags', [])])}
                </div>
            </div>
        </div>
    </div>
</main>
"""
            with open(page_path, 'w', encoding='utf-8') as f:
                f.write(header + item_html_content + footer)
            print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    def _generate_tag_pages(products):
        """ã‚¿ã‚°ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
        all_tags = sorted(list(set(tag for product in products for tag in product.get('tags', []))))
        total_tag_pages = math.ceil(len(all_tags) / TAGS_PER_PAGE)
        os.makedirs('tags', exist_ok=True)
        
        # ã‚¿ã‚°ä¸€è¦§ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ
        for i in range(total_tag_pages):
            start_index = i * TAGS_PER_PAGE
            end_index = start_index + TAGS_PER_PAGE
            paginated_tags = all_tags[start_index:end_index]
            page_num = i + 1
            page_path = 'tags/index.html' if page_num == 1 else f'tags/page{page_num}.html'
            tag_list_html_content = f"""
<main class="container">
    <div class="ai-recommendation-section">
        <h2 class="ai-section-title">ã‚¿ã‚°ã‹ã‚‰æ¢ã™</h2>
        <div class="product-tags all-tags-list">
            {"".join([f'<a href="{tag.replace(" ", "")}.html" class="tag-button">#{tag}</a>' for tag in paginated_tags])}
        </div>
    </div>
</main>
"""
            pagination_html = ""
            if total_tag_pages > 1:
                pagination_html += '<div class="pagination">'
                if page_num > 1:
                    prev_link = 'index.html' if page_num == 2 else f'page{page_num - 1}.html'
                    pagination_html += f'<a href="{prev_link}" class="prev">å‰ã¸</a>'
                for p in range(1, total_tag_pages + 1):
                    page_link = 'index.html' if p == 1 else f'page{p}.html'
                    active_class = 'active' if p == page_num else ''
                    pagination_html += f'<a href="{page_link}" class="{active_class}">{p}</a>'
                if page_num < total_tag_pages:
                    next_link = f'page{page_num + 1}.html'
                    pagination_html += f'<a href="{next_link}" class="next">æ¬¡ã¸</a>'
                pagination_html += '</div>'
            tag_header, tag_footer = _generate_header_footer(page_path, page_title="ã‚¿ã‚°ä¸€è¦§")
            with open(page_path, 'w', encoding='utf-8') as f:
                f.write(tag_header + tag_list_html_content + pagination_html + tag_footer)
            print(f"ã‚¿ã‚°ãƒšãƒ¼ã‚¸: {page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
            
        # å€‹åˆ¥ã‚¿ã‚°ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ
        for tag in all_tags:
            tag_page_path = f'tags/{tag.replace(" ", "")}.html'
            tag_products = [product for product in products if tag in product.get('tags', [])]
            tag_page_content = f"""
<main class="container">
    <div class="ai-recommendation-section">
        <h2 class="ai-section-title">#{tag} ã®å•†å“ä¸€è¦§</h2>
        <div class="product-grid">
            {"".join([_generate_product_card_html(p, tag_page_path) for p in tag_products])}
        </div>
    </div>
</main>
"""
            tag_header, tag_footer = _generate_header_footer(tag_page_path, page_title=f"#{tag} ã®å•†å“ä¸€è¦§")
            with open(tag_page_path, 'w', encoding='utf-8') as f:
                f.write(tag_header + tag_page_content + tag_footer)
            print(f"ã‚¿ã‚°ãƒšãƒ¼ã‚¸: {tag_page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
    
    def _generate_static_pages():
        """é™çš„ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
        def generate_static_page(file_name, title, content_html):
            page_path = file_name
            header, footer = _generate_header_footer(page_path, page_title=title)
            with open(page_path, 'w', encoding='utf-8') as f:
                f.write(header + content_html + footer)
            print(f"{page_path} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
        
        contact_content = """
    <main class="container">
        <div class="static-content">
            <h1>ãŠå•ã„åˆã‚ã›</h1>
            <p>ã”è³ªå•ã‚„ã”è¦æœ›ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€ä»¥ä¸‹ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¾ã§ã”é€£çµ¡ãã ã•ã„ã€‚</p>
            <p>ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹: sokux001@gmail.com</p>
        </div>
    </main>
    """
        generate_static_page("contact.html", "ãŠå•ã„åˆã‚ã›", contact_content)
        privacy_content = """
    <main class="container">
        <div class="static-content">
            <h1>ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼</h1>
            <p>å½“ã‚µã‚¤ãƒˆã¯ã€Googleã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚åé›†ã•ã‚Œã‚‹æƒ…å ±ã‚„ãã®åˆ©ç”¨ç›®çš„ã«ã¤ã„ã¦ã¯ã€Googleã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã‚’ã”ç¢ºèªãã ã•ã„ã€‚</p>
            <p>å½“ã‚µã‚¤ãƒˆã¯ã€Amazon.co.jpã‚’å®£ä¼ã—ãƒªãƒ³ã‚¯ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã‚µã‚¤ãƒˆãŒç´¹ä»‹æ–™ã‚’ç²å¾—ã§ãã‚‹æ‰‹æ®µã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã«è¨­å®šã•ã‚ŒãŸã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã‚ã‚‹ã€Amazonã‚¢ã‚½ã‚·ã‚¨ã‚¤ãƒˆãƒ»ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å‚åŠ è€…ã§ã™ã€‚</p>
        </div>
    </main>
    """
        generate_static_page("privacy.html", "ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼", privacy_content)
        disclaimer_content = """
    <main class="container">
        <div class="static-content">
            <h1>å…è²¬äº‹é …</h1>
            <p>æœ¬ã‚µã‚¤ãƒˆã«æ²è¼‰ã•ã‚Œã¦ã„ã‚‹æƒ…å ±ã¯ã€æ­£ç¢ºæ€§ã‚„å®Œå…¨æ€§ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</p>
            <p>ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ã‚’é€šã˜ã¦è³¼å…¥ã•ã‚ŒãŸå•†å“ã«é–¢ã™ã‚‹ãƒˆãƒ©ãƒ–ãƒ«ã«ã¤ã„ã¦ã¯ã€å½“ã‚µã‚¤ãƒˆã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</p>
        </div>
    </main>
    """
        generate_static_page("disclaimer.html", "å…è²¬äº‹é …", disclaimer_content)
    
    def _create_sitemap(products, categories):
        """sitemap.xmlã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
        sitemap_content = '<?xml version="1.0" encoding="UTF-8"?>\n'
        sitemap_content += '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'
        sitemap_content += '  <url>\n'
        sitemap_content += f'    <loc>{BASE_URL}</loc>\n'
        sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
        sitemap_content += '    <changefreq>daily</changefreq>\n'
        sitemap_content += '    <priority>1.0</priority>\n'
        sitemap_content += '  </url>\n'
        
        for main_cat, sub_cats in categories.items():
            sitemap_content += '  <url>\n'
            sitemap_content += f'    <loc>{BASE_URL}category/{main_cat}/index.html</loc>\n'
            sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
            sitemap_content += '    <changefreq>daily</changefreq>\n'
            sitemap_content += '    <priority>0.8</priority>\n'
            sitemap_content += '  </url>\n'
            for sub_cat in sub_cats:
                sitemap_content += '  <url>\n'
                sitemap_content += f'    <loc>{BASE_URL}category/{main_cat}/{sub_cat.replace(" ", "")}.html</loc>\n'
                sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
                sitemap_content += '    <changefreq>daily</changefreq>\n'
                sitemap_content += '    <priority>0.7</priority>\n'
                sitemap_content += '  </url>\n'
        
        for product in products:
            sitemap_content += '  <url>\n'
            sitemap_content += f'    <loc>{BASE_URL}{product["page_url"]}</loc>\n'
            sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
            sitemap_content += '    <changefreq>daily</changefreq>\n'
            sitemap_content += '    <priority>0.6</priority>\n'
            sitemap_content += '  </url>\n'
            
        static_pages = ["privacy.html", "disclaimer.html", "contact.html"]
        for page in static_pages:
            sitemap_content += '  <url>\n'
            sitemap_content += f'    <loc>{BASE_URL}{page}</loc>\n'
            sitemap_content += f'    <lastmod>{date.today().isoformat()}</lastmod>\n'
            sitemap_content += '    <changefreq>monthly</changefreq>\n'
            sitemap_content += '    <priority>0.5</priority>\n'
            sitemap_content += '  </url>\n'
        sitemap_content += '</urlset>'
        with open('sitemap.xml', 'w', encoding='utf-8') as f:
            f.write(sitemap_content)
        print("sitemap.xml ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")

    # ãƒ¡ã‚¤ãƒ³ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
    _generate_index_pages(products)
    _generate_category_pages(products, categories)
    _generate_product_detail_pages(products)
    _generate_tag_pages(products)
    _generate_static_pages()
    _create_sitemap(products, categories)
    print("ã‚µã‚¤ãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    rakuten_products = fetch_rakuten_items()
    yahoo_products = fetch_yahoo_items()
    
    new_products = rakuten_products + yahoo_products
    
    products = update_products_json(new_products)
    generate_site(products)
